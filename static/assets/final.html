<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title></title>
  <style>
  @font-face {
  font-family: octicons-link;
  src: url(data:font/woff;charset=utf-8;base64,d09GRgABAAAAAAZwABAAAAAACFQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABEU0lHAAAGaAAAAAgAAAAIAAAAAUdTVUIAAAZcAAAACgAAAAoAAQAAT1MvMgAAAyQAAABJAAAAYFYEU3RjbWFwAAADcAAAAEUAAACAAJThvmN2dCAAAATkAAAABAAAAAQAAAAAZnBnbQAAA7gAAACyAAABCUM+8IhnYXNwAAAGTAAAABAAAAAQABoAI2dseWYAAAFsAAABPAAAAZwcEq9taGVhZAAAAsgAAAA0AAAANgh4a91oaGVhAAADCAAAABoAAAAkCA8DRGhtdHgAAAL8AAAADAAAAAwGAACfbG9jYQAAAsAAAAAIAAAACABiATBtYXhwAAACqAAAABgAAAAgAA8ASm5hbWUAAAToAAABQgAAAlXu73sOcG9zdAAABiwAAAAeAAAAME3QpOBwcmVwAAAEbAAAAHYAAAB/aFGpk3jaTY6xa8JAGMW/O62BDi0tJLYQincXEypYIiGJjSgHniQ6umTsUEyLm5BV6NDBP8Tpts6F0v+k/0an2i+itHDw3v2+9+DBKTzsJNnWJNTgHEy4BgG3EMI9DCEDOGEXzDADU5hBKMIgNPZqoD3SilVaXZCER3/I7AtxEJLtzzuZfI+VVkprxTlXShWKb3TBecG11rwoNlmmn1P2WYcJczl32etSpKnziC7lQyWe1smVPy/Lt7Kc+0vWY/gAgIIEqAN9we0pwKXreiMasxvabDQMM4riO+qxM2ogwDGOZTXxwxDiycQIcoYFBLj5K3EIaSctAq2kTYiw+ymhce7vwM9jSqO8JyVd5RH9gyTt2+J/yUmYlIR0s04n6+7Vm1ozezUeLEaUjhaDSuXHwVRgvLJn1tQ7xiuVv/ocTRF42mNgZGBgYGbwZOBiAAFGJBIMAAizAFoAAABiAGIAznjaY2BkYGAA4in8zwXi+W2+MjCzMIDApSwvXzC97Z4Ig8N/BxYGZgcgl52BCSQKAA3jCV8CAABfAAAAAAQAAEB42mNgZGBg4f3vACQZQABIMjKgAmYAKEgBXgAAeNpjYGY6wTiBgZWBg2kmUxoDA4MPhGZMYzBi1AHygVLYQUCaawqDA4PChxhmh/8ODDEsvAwHgMKMIDnGL0x7gJQCAwMAJd4MFwAAAHjaY2BgYGaA4DAGRgYQkAHyGMF8NgYrIM3JIAGVYYDT+AEjAwuDFpBmA9KMDEwMCh9i/v8H8sH0/4dQc1iAmAkALaUKLgAAAHjaTY9LDsIgEIbtgqHUPpDi3gPoBVyRTmTddOmqTXThEXqrob2gQ1FjwpDvfwCBdmdXC5AVKFu3e5MfNFJ29KTQT48Ob9/lqYwOGZxeUelN2U2R6+cArgtCJpauW7UQBqnFkUsjAY/kOU1cP+DAgvxwn1chZDwUbd6CFimGXwzwF6tPbFIcjEl+vvmM/byA48e6tWrKArm4ZJlCbdsrxksL1AwWn/yBSJKpYbq8AXaaTb8AAHja28jAwOC00ZrBeQNDQOWO//sdBBgYGRiYWYAEELEwMTE4uzo5Zzo5b2BxdnFOcALxNjA6b2ByTswC8jYwg0VlNuoCTWAMqNzMzsoK1rEhNqByEyerg5PMJlYuVueETKcd/89uBpnpvIEVomeHLoMsAAe1Id4AAAAAAAB42oWQT07CQBTGv0JBhagk7HQzKxca2sJCE1hDt4QF+9JOS0nbaaYDCQfwCJ7Au3AHj+LO13FMmm6cl7785vven0kBjHCBhfpYuNa5Ph1c0e2Xu3jEvWG7UdPDLZ4N92nOm+EBXuAbHmIMSRMs+4aUEd4Nd3CHD8NdvOLTsA2GL8M9PODbcL+hD7C1xoaHeLJSEao0FEW14ckxC+TU8TxvsY6X0eLPmRhry2WVioLpkrbp84LLQPGI7c6sOiUzpWIWS5GzlSgUzzLBSikOPFTOXqly7rqx0Z1Q5BAIoZBSFihQYQOOBEdkCOgXTOHA07HAGjGWiIjaPZNW13/+lm6S9FT7rLHFJ6fQbkATOG1j2OFMucKJJsxIVfQORl+9Jyda6Sl1dUYhSCm1dyClfoeDve4qMYdLEbfqHf3O/AdDumsjAAB42mNgYoAAZQYjBmyAGYQZmdhL8zLdDEydARfoAqIAAAABAAMABwAKABMAB///AA8AAQAAAAAAAAAAAAAAAAABAAAAAA==) format('woff');
}

.markdown-body .octicon {
  display: inline-block;
  fill: currentColor;
  vertical-align: text-bottom;
}

.markdown-body .anchor {
  float: left;
  line-height: 1;
  margin-left: -20px;
  padding-right: 4px;
}

.markdown-body .anchor:focus {
  outline: none;
}

.markdown-body h1 .octicon-link,
.markdown-body h2 .octicon-link,
.markdown-body h3 .octicon-link,
.markdown-body h4 .octicon-link,
.markdown-body h5 .octicon-link,
.markdown-body h6 .octicon-link {
  color: #1b1f23;
  vertical-align: middle;
  visibility: hidden;
}

.markdown-body h1:hover .anchor,
.markdown-body h2:hover .anchor,
.markdown-body h3:hover .anchor,
.markdown-body h4:hover .anchor,
.markdown-body h5:hover .anchor,
.markdown-body h6:hover .anchor {
  text-decoration: none;
}

.markdown-body h1:hover .anchor .octicon-link,
.markdown-body h2:hover .anchor .octicon-link,
.markdown-body h3:hover .anchor .octicon-link,
.markdown-body h4:hover .anchor .octicon-link,
.markdown-body h5:hover .anchor .octicon-link,
.markdown-body h6:hover .anchor .octicon-link {
  visibility: visible;
}

.markdown-body {
  -ms-text-size-adjust: 100%;
  -webkit-text-size-adjust: 100%;
  color: #24292e;
  line-height: 1.5;
  font-family: -apple-system,BlinkMacSystemFont,Segoe UI,Helvetica,Arial,sans-serif,Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol;
  font-size: 16px;
  line-height: 1.5;
  word-wrap: break-word;
}

.markdown-body .pl-c {
  color: #6a737d;
}

.markdown-body .pl-c1,
.markdown-body .pl-s .pl-v {
  color: #005cc5;
}

.markdown-body .pl-e,
.markdown-body .pl-en {
  color: #6f42c1;
}

.markdown-body .pl-s .pl-s1,
.markdown-body .pl-smi {
  color: #24292e;
}

.markdown-body .pl-ent {
  color: #22863a;
}

.markdown-body .pl-k {
  color: #d73a49;
}

.markdown-body .pl-pds,
.markdown-body .pl-s,
.markdown-body .pl-s .pl-pse .pl-s1,
.markdown-body .pl-sr,
.markdown-body .pl-sr .pl-cce,
.markdown-body .pl-sr .pl-sra,
.markdown-body .pl-sr .pl-sre {
  color: #032f62;
}

.markdown-body .pl-smw,
.markdown-body .pl-v {
  color: #e36209;
}

.markdown-body .pl-bu {
  color: #b31d28;
}

.markdown-body .pl-ii {
  background-color: #b31d28;
  color: #fafbfc;
}

.markdown-body .pl-c2 {
  background-color: #d73a49;
  color: #fafbfc;
}

.markdown-body .pl-c2:before {
  content: "^M";
}

.markdown-body .pl-sr .pl-cce {
  color: #22863a;
  font-weight: 700;
}

.markdown-body .pl-ml {
  color: #735c0f;
}

.markdown-body .pl-mh,
.markdown-body .pl-mh .pl-en,
.markdown-body .pl-ms {
  color: #005cc5;
  font-weight: 700;
}

.markdown-body .pl-mi {
  color: #24292e;
  font-style: italic;
}

.markdown-body .pl-mb {
  color: #24292e;
  font-weight: 700;
}

.markdown-body .pl-md {
  background-color: #ffeef0;
  color: #b31d28;
}

.markdown-body .pl-mi1 {
  background-color: #f0fff4;
  color: #22863a;
}

.markdown-body .pl-mc {
  background-color: #ffebda;
  color: #e36209;
}

.markdown-body .pl-mi2 {
  background-color: #005cc5;
  color: #f6f8fa;
}

.markdown-body .pl-mdr {
  color: #6f42c1;
  font-weight: 700;
}

.markdown-body .pl-ba {
  color: #586069;
}

.markdown-body .pl-sg {
  color: #959da5;
}

.markdown-body .pl-corl {
  color: #032f62;
  text-decoration: underline;
}

.markdown-body details {
  display: block;
}

.markdown-body summary {
  display: list-item;
}

.markdown-body a {
  background-color: transparent;
}

.markdown-body a:active,
.markdown-body a:hover {
  outline-width: 0;
}

.markdown-body strong {
  font-weight: inherit;
  font-weight: bolder;
}

.markdown-body h1 {
  font-size: 2em;
  margin: .67em 0;
}

.markdown-body img {
  border-style: none;
}

.markdown-body code,
.markdown-body kbd,
.markdown-body pre {
  font-family: monospace,monospace;
  font-size: 1em;
}

.markdown-body hr {
  box-sizing: content-box;
  height: 0;
  overflow: visible;
}

.markdown-body input {
  font: inherit;
  margin: 0;
}

.markdown-body input {
  overflow: visible;
}

.markdown-body [type=checkbox] {
  box-sizing: border-box;
  padding: 0;
}

.markdown-body * {
  box-sizing: border-box;
}

.markdown-body input {
  font-family: inherit;
  font-size: inherit;
  line-height: inherit;
}

.markdown-body a {
  color: #0366d6;
  text-decoration: none;
}

.markdown-body a:hover {
  text-decoration: underline;
}

.markdown-body strong {
  font-weight: 600;
}

.markdown-body hr {
  background: transparent;
  border: 0;
  border-bottom: 1px solid #dfe2e5;
  height: 0;
  margin: 15px 0;
  overflow: hidden;
}

.markdown-body hr:before {
  content: "";
  display: table;
}

.markdown-body hr:after {
  clear: both;
  content: "";
  display: table;
}

.markdown-body table {
  border-collapse: collapse;
  border-spacing: 0;
}

.markdown-body td,
.markdown-body th {
  padding: 0;
}

.markdown-body details summary {
  cursor: pointer;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  margin-bottom: 0;
  margin-top: 0;
}

.markdown-body h1 {
  font-size: 32px;
}

.markdown-body h1,
.markdown-body h2 {
  font-weight: 600;
}

.markdown-body h2 {
  font-size: 24px;
}

.markdown-body h3 {
  font-size: 20px;
}

.markdown-body h3,
.markdown-body h4 {
  font-weight: 600;
}

.markdown-body h4 {
  font-size: 16px;
}

.markdown-body h5 {
  font-size: 14px;
}

.markdown-body h5,
.markdown-body h6 {
  font-weight: 600;
}

.markdown-body h6 {
  font-size: 12px;
}

.markdown-body p {
  margin-bottom: 10px;
  margin-top: 0;
}

.markdown-body blockquote {
  margin: 0;
}

.markdown-body ol,
.markdown-body ul {
  margin-bottom: 0;
  margin-top: 0;
  padding-left: 0;
}

.markdown-body ol ol,
.markdown-body ul ol {
  list-style-type: lower-roman;
}

.markdown-body ol ol ol,
.markdown-body ol ul ol,
.markdown-body ul ol ol,
.markdown-body ul ul ol {
  list-style-type: lower-alpha;
}

.markdown-body dd {
  margin-left: 0;
}

.markdown-body code,
.markdown-body pre {
  font-family: SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace;
  font-size: 12px;
}

.markdown-body pre {
  margin-bottom: 0;
  margin-top: 0;
}

.markdown-body input::-webkit-inner-spin-button,
.markdown-body input::-webkit-outer-spin-button {
  -webkit-appearance: none;
  appearance: none;
  margin: 0;
}

.markdown-body .border {
  border: 1px solid #e1e4e8!important;
}

.markdown-body .border-0 {
  border: 0!important;
}

.markdown-body .border-bottom {
  border-bottom: 1px solid #e1e4e8!important;
}

.markdown-body .rounded-1 {
  border-radius: 3px!important;
}

.markdown-body .bg-white {
  background-color: #fff!important;
}

.markdown-body .bg-gray-light {
  background-color: #fafbfc!important;
}

.markdown-body .text-gray-light {
  color: #6a737d!important;
}

.markdown-body .mb-0 {
  margin-bottom: 0!important;
}

.markdown-body .my-2 {
  margin-bottom: 8px!important;
  margin-top: 8px!important;
}

.markdown-body .pl-0 {
  padding-left: 0!important;
}

.markdown-body .py-0 {
  padding-bottom: 0!important;
  padding-top: 0!important;
}

.markdown-body .pl-1 {
  padding-left: 4px!important;
}

.markdown-body .pl-2 {
  padding-left: 8px!important;
}

.markdown-body .py-2 {
  padding-bottom: 8px!important;
  padding-top: 8px!important;
}

.markdown-body .pl-3,
.markdown-body .px-3 {
  padding-left: 16px!important;
}

.markdown-body .px-3 {
  padding-right: 16px!important;
}

.markdown-body .pl-4 {
  padding-left: 24px!important;
}

.markdown-body .pl-5 {
  padding-left: 32px!important;
}

.markdown-body .pl-6 {
  padding-left: 40px!important;
}

.markdown-body .f6 {
  font-size: 12px!important;
}

.markdown-body .lh-condensed {
  line-height: 1.25!important;
}

.markdown-body .text-bold {
  font-weight: 600!important;
}

.markdown-body:before {
  content: "";
  display: table;
}

.markdown-body:after {
  clear: both;
  content: "";
  display: table;
}

.markdown-body>:first-child {
  margin-top: 0!important;
}

.markdown-body>:last-child {
  margin-bottom: 0!important;
}

.markdown-body a:not([href]) {
  color: inherit;
  text-decoration: none;
}

.markdown-body blockquote,
.markdown-body dl,
.markdown-body ol,
.markdown-body p,
.markdown-body pre,
.markdown-body table,
.markdown-body ul {
  margin-bottom: 16px;
  margin-top: 0;
}

.markdown-body hr {
  background-color: #e1e4e8;
  border: 0;
  height: .25em;
  margin: 24px 0;
  padding: 0;
}

.markdown-body blockquote {
  border-left: .25em solid #dfe2e5;
  color: #6a737d;
  padding: 0 1em;
}

.markdown-body blockquote>:first-child {
  margin-top: 0;
}

.markdown-body blockquote>:last-child {
  margin-bottom: 0;
}

.markdown-body kbd {
  background-color: #fafbfc;
  border: 1px solid #c6cbd1;
  border-bottom-color: #959da5;
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 #959da5;
  color: #444d56;
  display: inline-block;
  font-size: 11px;
  line-height: 10px;
  padding: 3px 5px;
  vertical-align: middle;
}

.markdown-body h1,
.markdown-body h2,
.markdown-body h3,
.markdown-body h4,
.markdown-body h5,
.markdown-body h6 {
  font-weight: 600;
  line-height: 1.25;
  margin-bottom: 16px;
  margin-top: 24px;
}

.markdown-body h1 {
  font-size: 2em;
}

.markdown-body h1,
.markdown-body h2 {
  border-bottom: 1px solid #eaecef;
  padding-bottom: .3em;
}

.markdown-body h2 {
  font-size: 1.5em;
}

.markdown-body h3 {
  font-size: 1.25em;
}

.markdown-body h4 {
  font-size: 1em;
}

.markdown-body h5 {
  font-size: .875em;
}

.markdown-body h6 {
  color: #6a737d;
  font-size: .85em;
}

.markdown-body ol,
.markdown-body ul {
  padding-left: 2em;
}

.markdown-body ol ol,
.markdown-body ol ul,
.markdown-body ul ol,
.markdown-body ul ul {
  margin-bottom: 0;
  margin-top: 0;
}

.markdown-body li {
  word-wrap: break-all;
}

.markdown-body li>p {
  margin-top: 16px;
}

.markdown-body li+li {
  margin-top: .25em;
}

.markdown-body dl {
  padding: 0;
}

.markdown-body dl dt {
  font-size: 1em;
  font-style: italic;
  font-weight: 600;
  margin-top: 16px;
  padding: 0;
}

.markdown-body dl dd {
  margin-bottom: 16px;
  padding: 0 16px;
}

.markdown-body table {
  display: block;
  overflow: auto;
  width: 100%;
}

.markdown-body table th {
  font-weight: 600;
}

.markdown-body table td,
.markdown-body table th {
  border: 1px solid #dfe2e5;
  padding: 6px 13px;
}

.markdown-body table tr {
  background-color: #fff;
  border-top: 1px solid #c6cbd1;
}

.markdown-body table tr:nth-child(2n) {
  background-color: #f6f8fa;
}

.markdown-body img {
  background-color: #fff;
  box-sizing: content-box;
  max-width: 100%;
}

.markdown-body img[align=right] {
  padding-left: 20px;
}

.markdown-body img[align=left] {
  padding-right: 20px;
}

.markdown-body code {
  background-color: rgba(27,31,35,.05);
  border-radius: 3px;
  font-size: 85%;
  margin: 0;
  padding: .2em .4em;
}

.markdown-body pre {
  word-wrap: normal;
}

.markdown-body pre>code {
  background: transparent;
  border: 0;
  font-size: 100%;
  margin: 0;
  padding: 0;
  white-space: pre;
  word-break: normal;
}

.markdown-body .highlight {
  margin-bottom: 16px;
}

.markdown-body .highlight pre {
  margin-bottom: 0;
  word-break: normal;
}

.markdown-body .highlight pre,
.markdown-body pre {
  background-color: #f6f8fa;
  border-radius: 3px;
  font-size: 85%;
  line-height: 1.45;
  overflow: auto;
  padding: 16px;
}

.markdown-body pre code {
  background-color: transparent;
  border: 0;
  display: inline;
  line-height: inherit;
  margin: 0;
  max-width: auto;
  overflow: visible;
  padding: 0;
  word-wrap: normal;
}

.markdown-body .commit-tease-sha {
  color: #444d56;
  display: inline-block;
  font-family: SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace;
  font-size: 90%;
}

.markdown-body .blob-wrapper {
  border-bottom-left-radius: 3px;
  border-bottom-right-radius: 3px;
  overflow-x: auto;
  overflow-y: hidden;
}

.markdown-body .blob-wrapper-embedded {
  max-height: 240px;
  overflow-y: auto;
}

.markdown-body .blob-num {
  -moz-user-select: none;
  -ms-user-select: none;
  -webkit-user-select: none;
  color: rgba(27,31,35,.3);
  cursor: pointer;
  font-family: SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace;
  font-size: 12px;
  line-height: 20px;
  min-width: 50px;
  padding-left: 10px;
  padding-right: 10px;
  text-align: right;
  user-select: none;
  vertical-align: top;
  white-space: nowrap;
  width: 1%;
}

.markdown-body .blob-num:hover {
  color: rgba(27,31,35,.6);
}

.markdown-body .blob-num:before {
  content: attr(data-line-number);
}

.markdown-body .blob-code {
  line-height: 20px;
  padding-left: 10px;
  padding-right: 10px;
  position: relative;
  vertical-align: top;
}

.markdown-body .blob-code-inner {
  color: #24292e;
  font-family: SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace;
  font-size: 12px;
  overflow: visible;
  white-space: pre;
  word-wrap: normal;
}

.markdown-body .pl-token.active,
.markdown-body .pl-token:hover {
  background: #ffea7f;
  cursor: pointer;
}

.markdown-body kbd {
  background-color: #fafbfc;
  border: 1px solid #d1d5da;
  border-bottom-color: #c6cbd1;
  border-radius: 3px;
  box-shadow: inset 0 -1px 0 #c6cbd1;
  color: #444d56;
  display: inline-block;
  font: 11px SFMono-Regular,Consolas,Liberation Mono,Menlo,Courier,monospace;
  line-height: 10px;
  padding: 3px 5px;
  vertical-align: middle;
}

.markdown-body :checked+.radio-label {
  border-color: #0366d6;
  position: relative;
  z-index: 1;
}

.markdown-body .tab-size[data-tab-size="1"] {
  -moz-tab-size: 1;
  tab-size: 1;
}

.markdown-body .tab-size[data-tab-size="2"] {
  -moz-tab-size: 2;
  tab-size: 2;
}

.markdown-body .tab-size[data-tab-size="3"] {
  -moz-tab-size: 3;
  tab-size: 3;
}

.markdown-body .tab-size[data-tab-size="4"] {
  -moz-tab-size: 4;
  tab-size: 4;
}

.markdown-body .tab-size[data-tab-size="5"] {
  -moz-tab-size: 5;
  tab-size: 5;
}

.markdown-body .tab-size[data-tab-size="6"] {
  -moz-tab-size: 6;
  tab-size: 6;
}

.markdown-body .tab-size[data-tab-size="7"] {
  -moz-tab-size: 7;
  tab-size: 7;
}

.markdown-body .tab-size[data-tab-size="8"] {
  -moz-tab-size: 8;
  tab-size: 8;
}

.markdown-body .tab-size[data-tab-size="9"] {
  -moz-tab-size: 9;
  tab-size: 9;
}

.markdown-body .tab-size[data-tab-size="10"] {
  -moz-tab-size: 10;
  tab-size: 10;
}

.markdown-body .tab-size[data-tab-size="11"] {
  -moz-tab-size: 11;
  tab-size: 11;
}

.markdown-body .tab-size[data-tab-size="12"] {
  -moz-tab-size: 12;
  tab-size: 12;
}

.markdown-body .task-list-item {
  list-style-type: none;
}

.markdown-body .task-list-item+.task-list-item {
  margin-top: 3px;
}

.markdown-body .task-list-item input {
  margin: 0 .2em .25em -1.6em;
  vertical-align: middle;
}

.markdown-body hr {
  border-bottom-color: #eee;
}

.markdown-body .pl-0 {
  padding-left: 0!important;
}

.markdown-body .pl-1 {
  padding-left: 4px!important;
}

.markdown-body .pl-2 {
  padding-left: 8px!important;
}

.markdown-body .pl-3 {
  padding-left: 16px!important;
}

.markdown-body .pl-4 {
  padding-left: 24px!important;
}

.markdown-body .pl-5 {
  padding-left: 32px!important;
}

.markdown-body .pl-6 {
  padding-left: 40px!important;
}

.markdown-body .pl-7 {
  padding-left: 48px!important;
}

.markdown-body .pl-8 {
  padding-left: 64px!important;
}

.markdown-body .pl-9 {
  padding-left: 80px!important;
}

.markdown-body .pl-10 {
  padding-left: 96px!important;
}

.markdown-body .pl-11 {
  padding-left: 112px!important;
}

.markdown-body .pl-12 {
  padding-left: 128px!important;
}

/*# sourceURL=webpack://./node_modules/github-markdown-css/github-markdown.css */
/*# sourceMappingURL=data:application/json;charset=utf-8;base64,{"version":3,"sources":["webpack://./node_modules/github-markdown-css/github-markdown.css"],"names":[],"mappings":"AAAA;EACE,0BAA0B;EAC1B,2DAAqtE;AACvtE;;AAEA;EACE,qBAAqB;EACrB,kBAAkB;EAClB,2BAA2B;AAC7B;;AAEA;EACE,WAAW;EACX,cAAc;EACd,kBAAkB;EAClB,kBAAkB;AACpB;;AAEA;EACE,aAAa;AACf;;AAEA;;;;;;EAME,cAAc;EACd,sBAAsB;EACtB,kBAAkB;AACpB;;AAEA;;;;;;EAME,qBAAqB;AACvB;;AAEA;;;;;;EAME,mBAAmB;AACrB;;AAEA;EACE,0BAA0B;EAC1B,8BAA8B;EAC9B,cAAc;EACd,gBAAgB;EAChB,kIAAkI;EAClI,eAAe;EACf,gBAAgB;EAChB,qBAAqB;AACvB;;AAEA;EACE,cAAc;AAChB;;AAEA;;EAEE,cAAc;AAChB;;AAEA;;EAEE,cAAc;AAChB;;AAEA;;EAEE,cAAc;AAChB;;AAEA;EACE,cAAc;AAChB;;AAEA;EACE,cAAc;AAChB;;AAEA;;;;;;;EAOE,cAAc;AAChB;;AAEA;;EAEE,cAAc;AAChB;;AAEA;EACE,cAAc;AAChB;;AAEA;EACE,yBAAyB;EACzB,cAAc;AAChB;;AAEA;EACE,yBAAyB;EACzB,cAAc;AAChB;;AAEA;EACE,aAAa;AACf;;AAEA;EACE,cAAc;EACd,gBAAgB;AAClB;;AAEA;EACE,cAAc;AAChB;;AAEA;;;EAGE,cAAc;EACd,gBAAgB;AAClB;;AAEA;EACE,cAAc;EACd,kBAAkB;AACpB;;AAEA;EACE,cAAc;EACd,gBAAgB;AAClB;;AAEA;EACE,yBAAyB;EACzB,cAAc;AAChB;;AAEA;EACE,yBAAyB;EACzB,cAAc;AAChB;;AAEA;EACE,yBAAyB;EACzB,cAAc;AAChB;;AAEA;EACE,yBAAyB;EACzB,cAAc;AAChB;;AAEA;EACE,cAAc;EACd,gBAAgB;AAClB;;AAEA;EACE,cAAc;AAChB;;AAEA;EACE,cAAc;AAChB;;AAEA;EACE,cAAc;EACd,0BAA0B;AAC5B;;AAEA;EACE,cAAc;AAChB;;AAEA;EACE,kBAAkB;AACpB;;AAEA;EACE,6BAA6B;AAC/B;;AAEA;;EAEE,gBAAgB;AAClB;;AAEA;EACE,oBAAoB;EACpB,mBAAmB;AACrB;;AAEA;EACE,cAAc;EACd,eAAe;AACjB;;AAEA;EACE,kBAAkB;AACpB;;AAEA;;;EAGE,gCAAgC;EAChC,cAAc;AAChB;;AAEA;EACE,uBAAuB;EACvB,SAAS;EACT,iBAAiB;AACnB;;AAEA;EACE,aAAa;EACb,SAAS;AACX;;AAEA;EACE,iBAAiB;AACnB;;AAEA;EACE,sBAAsB;EACtB,UAAU;AACZ;;AAEA;EACE,sBAAsB;AACxB;;AAEA;EACE,oBAAoB;EACpB,kBAAkB;EAClB,oBAAoB;AACtB;;AAEA;EACE,cAAc;EACd,qBAAqB;AACvB;;AAEA;EACE,0BAA0B;AAC5B;;AAEA;EACE,gBAAgB;AAClB;;AAEA;EACE,uBAAuB;EACvB,SAAS;EACT,gCAAgC;EAChC,SAAS;EACT,cAAc;EACd,gBAAgB;AAClB;;AAEA;EACE,WAAW;EACX,cAAc;AAChB;;AAEA;EACE,WAAW;EACX,WAAW;EACX,cAAc;AAChB;;AAEA;EACE,yBAAyB;EACzB,iBAAiB;AACnB;;AAEA;;EAEE,UAAU;AACZ;;AAEA;EACE,eAAe;AACjB;;AAEA;;;;;;EAME,gBAAgB;EAChB,aAAa;AACf;;AAEA;EACE,eAAe;AACjB;;AAEA;;EAEE,gBAAgB;AAClB;;AAEA;EACE,eAAe;AACjB;;AAEA;EACE,eAAe;AACjB;;AAEA;;EAEE,gBAAgB;AAClB;;AAEA;EACE,eAAe;AACjB;;AAEA;EACE,eAAe;AACjB;;AAEA;;EAEE,gBAAgB;AAClB;;AAEA;EACE,eAAe;AACjB;;AAEA;EACE,mBAAmB;EACnB,aAAa;AACf;;AAEA;EACE,SAAS;AACX;;AAEA;;EAEE,gBAAgB;EAChB,aAAa;EACb,eAAe;AACjB;;AAEA;;EAEE,4BAA4B;AAC9B;;AAEA;;;;EAIE,4BAA4B;AAC9B;;AAEA;EACE,cAAc;AAChB;;AAEA;;EAEE,4EAA4E;EAC5E,eAAe;AACjB;;AAEA;EACE,gBAAgB;EAChB,aAAa;AACf;;AAEA;;EAEE,wBAAwB;EACxB,gBAAgB;EAChB,SAAS;AACX;;AAEA;EACE,mCAAmC;AACrC;;AAEA;EACE,mBAAmB;AACrB;;AAEA;EACE,0CAA0C;AAC5C;;AAEA;EACE,4BAA4B;AAC9B;;AAEA;EACE,gCAAgC;AAClC;;AAEA;EACE,mCAAmC;AACrC;;AAEA;EACE,wBAAwB;AAC1B;;AAEA;EACE,0BAA0B;AAC5B;;AAEA;EACE,4BAA4B;EAC5B,yBAAyB;AAC3B;;AAEA;EACE,yBAAyB;AAC3B;;AAEA;EACE,2BAA2B;EAC3B,wBAAwB;AAC1B;;AAEA;EACE,2BAA2B;AAC7B;;AAEA;EACE,2BAA2B;AAC7B;;AAEA;EACE,6BAA6B;EAC7B,0BAA0B;AAC5B;;AAEA;;EAEE,4BAA4B;AAC9B;;AAEA;EACE,6BAA6B;AAC/B;;AAEA;EACE,4BAA4B;AAC9B;;AAEA;EACE,4BAA4B;AAC9B;;AAEA;EACE,4BAA4B;AAC9B;;AAEA;EACE,yBAAyB;AAC3B;;AAEA;EACE,2BAA2B;AAC7B;;AAEA;EACE,0BAA0B;AAC5B;;AAEA;EACE,WAAW;EACX,cAAc;AAChB;;AAEA;EACE,WAAW;EACX,WAAW;EACX,cAAc;AAChB;;AAEA;EACE,uBAAuB;AACzB;;AAEA;EACE,0BAA0B;AAC5B;;AAEA;EACE,cAAc;EACd,qBAAqB;AACvB;;AAEA;;;;;;;EAOE,mBAAmB;EACnB,aAAa;AACf;;AAEA;EACE,yBAAyB;EACzB,SAAS;EACT,aAAa;EACb,cAAc;EACd,UAAU;AACZ;;AAEA;EACE,gCAAgC;EAChC,cAAc;EACd,cAAc;AAChB;;AAEA;EACE,aAAa;AACf;;AAEA;EACE,gBAAgB;AAClB;;AAEA;EACE,yBAAyB;EACzB,yBAAyB;EACzB,4BAA4B;EAC5B,kBAAkB;EAClB,kCAAkC;EAClC,cAAc;EACd,qBAAqB;EACrB,eAAe;EACf,iBAAiB;EACjB,gBAAgB;EAChB,sBAAsB;AACxB;;AAEA;;;;;;EAME,gBAAgB;EAChB,iBAAiB;EACjB,mBAAmB;EACnB,gBAAgB;AAClB;;AAEA;EACE,cAAc;AAChB;;AAEA;;EAEE,gCAAgC;EAChC,oBAAoB;AACtB;;AAEA;EACE,gBAAgB;AAClB;;AAEA;EACE,iBAAiB;AACnB;;AAEA;EACE,cAAc;AAChB;;AAEA;EACE,iBAAiB;AACnB;;AAEA;EACE,cAAc;EACd,gBAAgB;AAClB;;AAEA;;EAEE,iBAAiB;AACnB;;AAEA;;;;EAIE,gBAAgB;EAChB,aAAa;AACf;;AAEA;EACE,oBAAoB;AACtB;;AAEA;EACE,gBAAgB;AAClB;;AAEA;EACE,iBAAiB;AACnB;;AAEA;EACE,UAAU;AACZ;;AAEA;EACE,cAAc;EACd,kBAAkB;EAClB,gBAAgB;EAChB,gBAAgB;EAChB,UAAU;AACZ;;AAEA;EACE,mBAAmB;EACnB,eAAe;AACjB;;AAEA;EACE,cAAc;EACd,cAAc;EACd,WAAW;AACb;;AAEA;EACE,gBAAgB;AAClB;;AAEA;;EAEE,yBAAyB;EACzB,iBAAiB;AACnB;;AAEA;EACE,sBAAsB;EACtB,6BAA6B;AAC/B;;AAEA;EACE,yBAAyB;AAC3B;;AAEA;EACE,sBAAsB;EACtB,uBAAuB;EACvB,eAAe;AACjB;;AAEA;EACE,kBAAkB;AACpB;;AAEA;EACE,mBAAmB;AACrB;;AAEA;EACE,oCAAoC;EACpC,kBAAkB;EAClB,cAAc;EACd,SAAS;EACT,kBAAkB;AACpB;;AAEA;EACE,iBAAiB;AACnB;;AAEA;EACE,uBAAuB;EACvB,SAAS;EACT,eAAe;EACf,SAAS;EACT,UAAU;EACV,gBAAgB;EAChB,kBAAkB;AACpB;;AAEA;EACE,mBAAmB;AACrB;;AAEA;EACE,gBAAgB;EAChB,kBAAkB;AACpB;;AAEA;;EAEE,yBAAyB;EACzB,kBAAkB;EAClB,cAAc;EACd,iBAAiB;EACjB,cAAc;EACd,aAAa;AACf;;AAEA;EACE,6BAA6B;EAC7B,SAAS;EACT,eAAe;EACf,oBAAoB;EACpB,SAAS;EACT,eAAe;EACf,iBAAiB;EACjB,UAAU;EACV,iBAAiB;AACnB;;AAEA;EACE,cAAc;EACd,qBAAqB;EACrB,4EAA4E;EAC5E,cAAc;AAChB;;AAEA;EACE,8BAA8B;EAC9B,+BAA+B;EAC/B,gBAAgB;EAChB,kBAAkB;AACpB;;AAEA;EACE,iBAAiB;EACjB,gBAAgB;AAClB;;AAEA;EACE,sBAAsB;EACtB,qBAAqB;EACrB,yBAAyB;EACzB,wBAAwB;EACxB,eAAe;EACf,4EAA4E;EAC5E,eAAe;EACf,iBAAiB;EACjB,eAAe;EACf,kBAAkB;EAClB,mBAAmB;EACnB,iBAAiB;EACjB,iBAAiB;EACjB,mBAAmB;EACnB,mBAAmB;EACnB,SAAS;AACX;;AAEA;EACE,wBAAwB;AAC1B;;AAEA;EACE,+BAA+B;AACjC;;AAEA;EACE,iBAAiB;EACjB,kBAAkB;EAClB,mBAAmB;EACnB,kBAAkB;EAClB,mBAAmB;AACrB;;AAEA;EACE,cAAc;EACd,4EAA4E;EAC5E,eAAe;EACf,iBAAiB;EACjB,gBAAgB;EAChB,iBAAiB;AACnB;;AAEA;;EAEE,mBAAmB;EACnB,eAAe;AACjB;;AAEA;EACE,yBAAyB;EACzB,yBAAyB;EACzB,4BAA4B;EAC5B,kBAAkB;EAClB,kCAAkC;EAClC,cAAc;EACd,qBAAqB;EACrB,0EAA0E;EAC1E,iBAAiB;EACjB,gBAAgB;EAChB,sBAAsB;AACxB;;AAEA;EACE,qBAAqB;EACrB,kBAAkB;EAClB,UAAU;AACZ;;AAEA;EACE,gBAAgB;EAChB,WAAW;AACb;;AAEA;EACE,gBAAgB;EAChB,WAAW;AACb;;AAEA;EACE,gBAAgB;EAChB,WAAW;AACb;;AAEA;EACE,gBAAgB;EAChB,WAAW;AACb;;AAEA;EACE,gBAAgB;EAChB,WAAW;AACb;;AAEA;EACE,gBAAgB;EAChB,WAAW;AACb;;AAEA;EACE,gBAAgB;EAChB,WAAW;AACb;;AAEA;EACE,gBAAgB;EAChB,WAAW;AACb;;AAEA;EACE,gBAAgB;EAChB,WAAW;AACb;;AAEA;EACE,iBAAiB;EACjB,YAAY;AACd;;AAEA;EACE,iBAAiB;EACjB,YAAY;AACd;;AAEA;EACE,iBAAiB;EACjB,YAAY;AACd;;AAEA;EACE,qBAAqB;AACvB;;AAEA;EACE,eAAe;AACjB;;AAEA;EACE,2BAA2B;EAC3B,sBAAsB;AACxB;;AAEA;EACE,yBAAyB;AAC3B;;AAEA;EACE,yBAAyB;AAC3B;;AAEA;EACE,2BAA2B;AAC7B;;AAEA;EACE,2BAA2B;AAC7B;;AAEA;EACE,4BAA4B;AAC9B;;AAEA;EACE,4BAA4B;AAC9B;;AAEA;EACE,4BAA4B;AAC9B;;AAEA;EACE,4BAA4B;AAC9B;;AAEA;EACE,4BAA4B;AAC9B;;AAEA;EACE,4BAA4B;AAC9B;;AAEA;EACE,4BAA4B;AAC9B;;AAEA;EACE,4BAA4B;AAC9B;;AAEA;EACE,6BAA6B;AAC/B;;AAEA;EACE,6BAA6B;AAC/B","sourceRoot":""} */
  </style>
  <style>
  /**
 * prism.js default theme for JavaScript, CSS and HTML
 * Based on dabblet (http://dabblet.com)
 * @author Lea Verou
 */

code[class*="language-"],
pre[class*="language-"] {
	color: black;
	background: none;
	text-shadow: 0 1px white;
	font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
	font-size: 1em;
	text-align: left;
	white-space: pre;
	word-spacing: normal;
	word-break: normal;
	word-wrap: normal;
	line-height: 1.5;

	-moz-tab-size: 4;
	-o-tab-size: 4;
	tab-size: 4;

	-webkit-hyphens: none;
	-moz-hyphens: none;
	-ms-hyphens: none;
	hyphens: none;
}

pre[class*="language-"]::-moz-selection, pre[class*="language-"] ::-moz-selection,
code[class*="language-"]::-moz-selection, code[class*="language-"] ::-moz-selection {
	text-shadow: none;
	background: #b3d4fc;
}

pre[class*="language-"]::selection, pre[class*="language-"] ::selection,
code[class*="language-"]::selection, code[class*="language-"] ::selection {
	text-shadow: none;
	background: #b3d4fc;
}

@media print {
	code[class*="language-"],
	pre[class*="language-"] {
		text-shadow: none;
	}
}

/* Code blocks */
pre[class*="language-"] {
	padding: 1em;
	margin: .5em 0;
	overflow: auto;
}

:not(pre) > code[class*="language-"],
pre[class*="language-"] {
	background: #f5f2f0;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
	padding: .1em;
	border-radius: .3em;
	white-space: normal;
}

.token.comment,
.token.prolog,
.token.doctype,
.token.cdata {
	color: slategray;
}

.token.punctuation {
	color: #999;
}

.token.namespace {
	opacity: .7;
}

.token.property,
.token.tag,
.token.boolean,
.token.number,
.token.constant,
.token.symbol,
.token.deleted {
	color: #905;
}

.token.selector,
.token.attr-name,
.token.string,
.token.char,
.token.builtin,
.token.inserted {
	color: #690;
}

.token.operator,
.token.entity,
.token.url,
.language-css .token.string,
.style .token.string {
	color: #9a6e3a;
	/* This background color was intended by the author of this theme. */
	background: hsla(0, 0%, 100%, .5);
}

.token.atrule,
.token.attr-value,
.token.keyword {
	color: #07a;
}

.token.function,
.token.class-name {
	color: #DD4A68;
}

.token.regex,
.token.important,
.token.variable {
	color: #e90;
}

.token.important,
.token.bold {
	font-weight: bold;
}
.token.italic {
	font-style: italic;
}

.token.entity {
	cursor: help;
}

/*# sourceURL=webpack://./node_modules/prismjs/themes/prism.css */
/*# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjozLCJzb3VyY2VzIjpbIndlYnBhY2s6Ly8uL25vZGVfbW9kdWxlcy9wcmlzbWpzL3RoZW1lcy9wcmlzbS5jc3MiXSwibmFtZXMiOltdLCJtYXBwaW5ncyI6IkFBQUE7Ozs7RUFJRTs7QUFFRjs7Q0FFQyxZQUFZO0NBQ1osZ0JBQWdCO0NBQ2hCLHdCQUF3QjtDQUN4QixzRUFBc0U7Q0FDdEUsY0FBYztDQUNkLGdCQUFnQjtDQUNoQixnQkFBZ0I7Q0FDaEIsb0JBQW9CO0NBQ3BCLGtCQUFrQjtDQUNsQixpQkFBaUI7Q0FDakIsZ0JBQWdCOztDQUVoQixnQkFBZ0I7Q0FDaEIsY0FBYztDQUNkLFdBQVc7O0NBRVgscUJBQXFCO0NBQ3JCLGtCQUFrQjtDQUNsQixpQkFBaUI7Q0FDakIsYUFBYTtBQUNkOztBQUVBOztDQUVDLGlCQUFpQjtDQUNqQixtQkFBbUI7QUFDcEI7O0FBRUE7O0NBRUMsaUJBQWlCO0NBQ2pCLG1CQUFtQjtBQUNwQjs7QUFFQTtDQUNDOztFQUVDLGlCQUFpQjtDQUNsQjtBQUNEOztBQUVBLGdCQUFnQjtBQUNoQjtDQUNDLFlBQVk7Q0FDWixjQUFjO0NBQ2QsY0FBYztBQUNmOztBQUVBOztDQUVDLG1CQUFtQjtBQUNwQjs7QUFFQSxnQkFBZ0I7QUFDaEI7Q0FDQyxhQUFhO0NBQ2IsbUJBQW1CO0NBQ25CLG1CQUFtQjtBQUNwQjs7QUFFQTs7OztDQUlDLGdCQUFnQjtBQUNqQjs7QUFFQTtDQUNDLFdBQVc7QUFDWjs7QUFFQTtDQUNDLFdBQVc7QUFDWjs7QUFFQTs7Ozs7OztDQU9DLFdBQVc7QUFDWjs7QUFFQTs7Ozs7O0NBTUMsV0FBVztBQUNaOztBQUVBOzs7OztDQUtDLGNBQWM7Q0FDZCxvRUFBb0U7Q0FDcEUsaUNBQWlDO0FBQ2xDOztBQUVBOzs7Q0FHQyxXQUFXO0FBQ1o7O0FBRUE7O0NBRUMsY0FBYztBQUNmOztBQUVBOzs7Q0FHQyxXQUFXO0FBQ1o7O0FBRUE7O0NBRUMsaUJBQWlCO0FBQ2xCO0FBQ0E7Q0FDQyxrQkFBa0I7QUFDbkI7O0FBRUE7Q0FDQyxZQUFZO0FBQ2IiLCJzb3VyY2VSb290IjoiIn0= */
  </style>
  <style>
  
  </style>
  <style>
    .markdown-body {
      font-family: -apple-system,Segoe UI,Helvetica,Arial,sans-serif,Apple Color Emoji,Segoe UI Emoji;
      box-sizing: border-box;
      min-width: 200px;
      max-width: 980px;
      margin: 0 auto;
      padding: 45px;
    }

    @media not print {
      .markdown-body {
        padding: 45px;
      }

      @media (max-width: 767px) {
        .markdown-body {
          padding: 15px;
        }
      }
    }

    .hf-container {
      color: #24292e;
      line-height: 1.3;
    }

    .markdown-body .highlight pre,
    .markdown-body pre {
      white-space: pre-wrap;
    }
    .markdown-body table {
      display: table;
    }
    .markdown-body img[data-align="center"] {
      display: block;
      margin: 0 auto;
    }
    .markdown-body img[data-align="right"] {
      display: block;
      margin: 0 0 0 auto;
    }
    .markdown-body li.task-list-item {
      list-style-type: none;
    }
    .markdown-body li > [type=checkbox] {
      margin: 0 0 0 -1.3em;
    }
    .markdown-body input[type="checkbox"] ~ p {
      margin-top: 0;
      display: inline-block;
    }
    .markdown-body ol ol,
    .markdown-body ul ol {
      list-style-type: decimal;
    }
    .markdown-body ol ol ol,
    .markdown-body ol ul ol,
    .markdown-body ul ol ol,
    .markdown-body ul ul ol {
      list-style-type: decimal;
    }
  </style>
  <style>.markdown-body a.footnote-ref {
  text-decoration: none;
}

.footnotes {
  font-size: .85em;
  opacity: .8;
}

.footnotes li[role="doc-endnote"] {
  position: relative;
}

.footnotes .footnote-back {
  position: absolute;
  font-family: initial;
  top: .2em;
  right: 1em;
  text-decoration: none;
}

.inline-math.invalid,
.multiple-math.invalid {
  color: rgb(255, 105, 105);
}

.toc-container {
  width: 100%;
}

.toc-container .toc-title {
  font-weight: 700;
  font-size: 1.2em;
  margin-bottom: 0;
}

.toc-container li,
.toc-container ul,
.toc-container ul li {
  list-style: none !important;
}

.toc-container > ul {
  padding-left: 0;
}

.toc-container ul li span {
  display : flex;
}

.toc-container ul li span a {
  color: inherit;
  text-decoration: none;
}
.toc-container ul li span a:hover {
  color: inherit;
  text-decoration: none;
}

.toc-container ul li span span.dots {
  flex: 1;
  height: 0.65em;
  margin: 0 10px;
  border-bottom: 2px dotted black;
}

/*# sourceURL=webpack://./src/muya/lib/assets/styles/exportStyle.css */
/*# sourceMappingURL=data:application/json;charset=utf-8;base64,eyJ2ZXJzaW9uIjozLCJzb3VyY2VzIjpbIndlYnBhY2s6Ly8uL3NyYy9tdXlhL2xpYi9hc3NldHMvc3R5bGVzL2V4cG9ydFN0eWxlLmNzcyJdLCJuYW1lcyI6W10sIm1hcHBpbmdzIjoiQUFBQTtFQUNFLHFCQUFxQjtBQUN2Qjs7QUFFQTtFQUNFLGdCQUFnQjtFQUNoQixXQUFXO0FBQ2I7O0FBRUE7RUFDRSxrQkFBa0I7QUFDcEI7O0FBRUE7RUFDRSxrQkFBa0I7RUFDbEIsb0JBQW9CO0VBQ3BCLFNBQVM7RUFDVCxVQUFVO0VBQ1YscUJBQXFCO0FBQ3ZCOztBQUVBOztFQUVFLHlCQUF5QjtBQUMzQjs7QUFFQTtFQUNFLFdBQVc7QUFDYjs7QUFFQTtFQUNFLGdCQUFnQjtFQUNoQixnQkFBZ0I7RUFDaEIsZ0JBQWdCO0FBQ2xCOztBQUVBOzs7RUFHRSwyQkFBMkI7QUFDN0I7O0FBRUE7RUFDRSxlQUFlO0FBQ2pCOztBQUVBO0VBQ0UsY0FBYztBQUNoQjs7QUFFQTtFQUNFLGNBQWM7RUFDZCxxQkFBcUI7QUFDdkI7QUFDQTtFQUNFLGNBQWM7RUFDZCxxQkFBcUI7QUFDdkI7O0FBRUE7RUFDRSxPQUFPO0VBQ1AsY0FBYztFQUNkLGNBQWM7RUFDZCwrQkFBK0I7QUFDakMiLCJzb3VyY2VSb290IjoiIn0= */</style>
  <style>.markdown-body{}pre.front-matter{display:none!important;}</style>
</head>
<body>
  <article class="markdown-body"><h1 class="atx" id="15618-project-final-report----ray-tracing-in-cuda">15618 Project Final Report -- Ray Tracing in CUDA</h1>
<p>Jiaqi Song (<a href="mailto:jiaqison@andrew.cmu.edu">jiaqison@andrew.cmu.edu</a>)</p>
<p>Xinping Luo (<a href="mailto:xinpingl@andrew.cmu.edu">xinpingl@andrew.cmu.edu</a>)</p>
<h2 class="atx" id="url-ray-tracing-in-cuda-raytracingcudagithubio">URL: <a href="https://raytracingcuda.github.io/">Ray Tracing in CUDA (raytracingcuda.github.io)</a></h2>
<h2 class="atx" id="github-jiaqi1songraytracing-githubcom">GITHUB: <a href="https://github.com/Jiaqi1song/RayTracing">Jiaqi1song/RayTracing (github.com)</a></h2>
<h2 class="atx" id="summary">Summary</h2>
<p>Our project implements a GPU-based ray tracer based on the CPU code (baseline) of three books in "Ray Tracing in One Weekend" series. We compare the performance of baseline code, OpenMP parallelized code and CUDA parallelized code and achieve a maximum of 8612x times speedup in four test scenes.</p>
<h2 class="atx" id="background">Background</h2>
<h3 class="atx" id="basic-knowledge-of-ray-tracing">Basic Knowledge of Ray Tracing</h3>
<blockquote>
<p>Rendering is a critical process in computer graphics, converting 3D models into 2D scenes. Compared with rasterization, ray tracing offers more photorealistic results by simulating how rays of light interact with objects in a scene, tracing their paths as they reflect, refract, or are absorbed by materials. <strong>As a result, ray tracing achieves realistic lighting, shadows, and reflections, making it the preferred method for high-quality rendering in film and visual effects.</strong></p>
</blockquote>
<img data-align="center" alt="ray-tracing-image.jpg" src="../images/ray-tracing-image.jpg" title="">

<p>The above image adopted from <code>Nvidia Developer</code> provides an intuitive understanding of how ray tracing works. In detail, rays are cast from a camera through each pixel on the screen into the scene, following a path that simulates how light travels in the real world. When a ray hits an object, it can reflect (bounce off the surface), refract (pass through transparent objects), or terminate if it absorbs into a surface. Reflection is calculated based on the surface’s material and angle, leading to mirror-like or glossy reflections. Refraction occurs in transparent materials, bending rays as they pass through surfaces like glass or water. This process of tracing rays through multiple reflections and refractions enables realistic rendering of complex light interactions, contributing to the high visual quality of ray tracing.</p>
<h3 class="atx" id="basic-algorithm-of-ray-tracing">Basic Algorithm of Ray Tracing</h3>
<p>The following pseudocode presents the basic algorithm of ray tracing renering.</p>
<pre><code class="fenced-code-block language-python"><span class="token comment"># Iterate through objects in the world and find the closest hit</span>
<span class="token keyword">def</span> <span class="token function">world_hit</span><span class="token punctuation">(</span>ray<span class="token punctuation">,</span> rec<span class="token punctuation">)</span><span class="token punctuation">:</span>
    closest_hit <span class="token operator">=</span> <span class="token boolean">None</span>
    <span class="token keyword">for</span> <span class="token builtin">object</span> <span class="token keyword">in</span> world<span class="token punctuation">:</span>
        <span class="token keyword">if</span> ray hits <span class="token builtin">object</span> <span class="token keyword">and</span> <span class="token builtin">object</span> <span class="token keyword">is</span> closer than closest_hit<span class="token punctuation">:</span>
            closet_hit <span class="token operator">=</span> <span class="token builtin">object</span>
    <span class="token keyword">if</span> closest_hit <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        <span class="token comment"># Record the detail of the final hit detail</span>
        rec <span class="token operator">=</span> closest_hit<span class="token punctuation">.</span>record<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> <span class="token boolean">True</span>
    <span class="token keyword">return</span> <span class="token boolean">False</span>

<span class="token comment"># Compute the color of a pixel by tracing the ray in the world</span>
<span class="token keyword">def</span> <span class="token function">ray_color</span><span class="token punctuation">(</span>depth<span class="token punctuation">,</span> ray<span class="token punctuation">,</span> world<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># If the recursion depth is zero or less, return black</span>
    <span class="token keyword">if</span> depth <span class="token operator">&lt;=</span><span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> Color<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>

    <span class="token comment"># Check if the ray hits anything in the world</span>
    <span class="token keyword">if</span> world_hit<span class="token punctuation">(</span>ray<span class="token punctuation">,</span> rec<span class="token punctuation">)</span><span class="token punctuation">:</span>
        material <span class="token operator">=</span> rec<span class="token punctuation">.</span>material
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> background_color <span class="token comment"># Return the background color if no hit</span>

    <span class="token comment"># Compute the emitted color from the material</span>
    <span class="token comment"># Only light source emit color</span>
    <span class="token comment"># If this color is not black, then the ray just hits a light source</span>
    emitted_color <span class="token operator">=</span> material<span class="token punctuation">.</span>emit<span class="token punctuation">(</span><span class="token punctuation">)</span> 

    <span class="token comment"># Check if the material scatters the ray</span>
    <span class="token keyword">if</span> material<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        attenuation<span class="token punctuation">,</span> scattered_ray <span class="token operator">=</span> ScatterRecord<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> emitted_color  <span class="token comment"># Return emitted color if no scattering</span>

    <span class="token comment"># The ray continues to travel in the world</span>
    <span class="token keyword">return</span> emitted_color <span class="token operator">+</span> attenuation <span class="token operator">*</span> \
        ray_color<span class="token punctuation">(</span>depth <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> scattered_ray<span class="token punctuation">,</span> world<span class="token punctuation">)</span>

<span class="token comment"># Rendering each pixel independently</span>
<span class="token keyword">for</span> pixel <span class="token keyword">in</span> image<span class="token punctuation">:</span>
    <span class="token comment"># Each pixel samples a number of rays for anti-aliasing</span>
    <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_samples_per_pixel<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># Monte Carlo sampling of rays from camera to pixel</span>
        ray <span class="token operator">=</span> SampleRayFromCameraToPixel<span class="token punctuation">(</span>pixel_coordinate<span class="token punctuation">)</span>
        <span class="token comment"># Calculate the color that this ray brings to the pixel</span>
        pixel_color <span class="token operator">+=</span> ray_color<span class="token punctuation">(</span>max_depth<span class="token punctuation">,</span> ray<span class="token punctuation">,</span> world<span class="token punctuation">)</span>
    <span class="token comment"># Take the average color of all sampled rays</span>
    pixel_color <span class="token operator">=</span> pixel_color <span class="token operator">/</span> num_samples_per_pixel</code></pre>
<p>The <code>ray_color</code> function computes the color of a pixel by tracing a ray through a 3D scene. The function begins by checking if the maximum recursion depth (<code>depth</code>) is reached, returning black if true. It then determines if the ray intersects any object in the scene (<code>world</code>). If no intersection occurs, the function returns the background color. The intersection check is performed by <code>world_hit</code> function and it iterates through all objects in the world and find a closest hit and record the hitted object. <strong>This brute force solution is searching in linear space and should be optimized using BVH.</strong></p>
<p>For intersections, the object's material properties are evaluated. If the material emits light, i.e. a light source, its emitted color is calculated. The function also checks if the material scatters the ray (e.g., reflection or refraction). If scattering occurs, a new ray is generated with reduced intensity (<code>attenuation</code>), and the function is recursively called with the scattered ray and decreased depth. The resulting color is a combination of the emitted color and the recursively calculated scattered light.</p>
<p>In the rendering loop, each pixel's color is computed by sampling multiple rays using Monte Carlo sampling for anti-aliasing. The final color of that pixel is the average color across sampled rays. <strong>It is worth noticing that this nested for loop can be fullly independent, which means that we can calculate each pixel independently, as well as calculating each sampled ray in a pixel independently with help of reduce sum. This independence is where massive thread parallelism can help computing many pixels/rays at the same time and speedup the application greatly.</strong></p>
<p>Since the ray tracing rendering involves branching in the code, techniquely the parallelism would be thread parallelism instead of data parallelism. For this reason, we use OpenMP to parallelize the code on CPU. Given the CUDA provides SIMT (Single Instruction, Multiple Threads) programing abstraction, the rendering algorithm is inherently more suitable on GPU for its capability of massive thread parallelism. Regarding locality, ray tracing exhibits poor spatial locality because rays often traverse different parts of the scene, leading to scattered memory accesses. However, temporal locality can be exploited for frequently accessed resources, such as the material data or texture data.</p>
<h3 class="atx" id="acceleration-structure-bounding-volume-hierarchies">Acceleration Structure:&nbsp;Bounding Volume Hierarchies</h3>
<p><strong>Bounding Volume Hierarchies (BVH) optimize the ray-object intersection checks by organizing objects into a hierarchical tree structure of bounding volumes, such as boxes.</strong> When a ray enters the scene, the BVH allows it to quickly bypass large areas without objects, only performing detailed intersection checks when necessary. This hierarchy significantly reduces computation time, especially in scenes with many objects.</p>
<h3 class="atx" id="sampling-techniques-in-ray-tracing">Sampling Techniques in Ray Tracing</h3>
<p>Sampling more rays in a pixel can improve rendering quality, but it also requires more computation time. Thus modern ray tracing relies on advanced sampling techniques to improve rendering quality. <strong>Sampling techniques reduce noise and enhance visual fidelity while maintaining computational efficiency.</strong> Our code combines three sampling techniques.</p>
<p><strong>Monte Carlo sampling</strong> is widely used in ray tracing to handle complex light transport equations. It generates random rays within a hemisphere or cone around a surface point to approximate indirect lighting, reflections, and refractions. By averaging multiple samples, the algorithm produces smoother results, reducing artifacts like jagged shadows or noisy reflections.</p>
<p><strong>Importance sampling</strong> optimizes the sampling process by prioritizing directions that contribute more significantly to the final image. Instead of sampling uniformly, it biases ray directions toward areas with higher light intensity or sharp features, such as specular highlights. This reduces variance and noise, especially in scenes with bright light sources.</p>
<p><strong>Light sampling</strong> focuses on improving the accuracy of direct illumination by explicitly sampling light sources in the scene. Rays are cast directly toward light sources to evaluate their contribution to a surface. This approach ensures accurate shadow rendering and reduces wasted computation on non-contributing areas.</p>
<p>The pseudocode of <code>ray_color</code> function considering the above sampling techniques can be found in <strong>APPENDIX</strong> section.</p>
<h2 class="atx" id="approach">APPROACH</h2>
<h3 class="atx" id="introduction">Introduction</h3>
<blockquote>
<p>In this section, we are first going to talk about how we parallelize the ray tracing using OpenMP on CPU and CUDA on GPU, then we are going to show an optimization of using BVH to accelerate the hit search. While rays in one pixel can also be parallelized, neither of the two parallelism we introduce takes it to this far.</p>
</blockquote>
<p>Our code is based on the CPU code of "Ray Tracing in One Weekend" series, which is the version of code that we call <code>Baseline</code> in the next section. Upon this code, we add support of triangle (mesh) object as well as animation of moving camera and moving object. Then based on this version, we add Openmp to the code with only the change of pragma. We call this version of code <code>OpenMP</code>, now to run the baseline code, we simply set the flag <code>use_openmp=false</code>.</p>
<p>The cuda code is a little different. To solve the several potential bugs resulting from its confusing definition of point, vector and color, we radically rewrite all those files and optimize the project structure regarding hittables, materials and utils. We supported random number generation and complex tree structure creation natively on GPU. Eventually, we manage to transplant most of the features supported on CPU to GPU, except for moving object, which requires more careful consideration of BVH reconstruction between frames. We this version of code <code>CUDA</code>.</p>
<p>We provide a <code>render.sh</code> for one to quick run and access the ray tracer on both CPU and GPU with various parameters for you to play with.</p>
<h3 class="atx" id="openmp-parallelism">OpenMP Parallelism</h3>
<p>In our project, OpenMP is utilized to parallelize the ray tracing rendering process on multi-core CPUs, leveraging task-level parallelism. By using OpenMP pragmas, the rendering loop is divided across available CPU cores, allowing multiple pixels to be processed simultaneously. <strong>Specifically, the <code>#pragma omp parallel for</code> directive is applied to the outer loop iterating over pixels, ensuring that each core handles a subset of the image pixels independently.</strong> The dynamic scheduling policy further balances the workload among cores by dynamically assigning pixels to threads as they become available, which is particularly beneficial for scenes with varying computational loads across pixels.</p>
<pre><code class="fenced-code-block language-python"><span class="token comment">#pragma omp parallel for schedule(dynamic)</span>
<span class="token keyword">for</span> pixel <span class="token keyword">in</span> image<span class="token punctuation">:</span>
    <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_samples_per_pixel<span class="token punctuation">)</span><span class="token punctuation">:</span>
        ray <span class="token operator">=</span> SampleRayFromCameraToPixel<span class="token punctuation">(</span>pixel_coordinate<span class="token punctuation">)</span>
        pixel_color <span class="token operator">+=</span> ray_color<span class="token punctuation">(</span>max_depth<span class="token punctuation">,</span> ray<span class="token punctuation">,</span> world<span class="token punctuation">)</span>
    pixel_color <span class="token operator">=</span> pixel_color <span class="token operator">/</span> num_samples_per_pixel</code></pre>
<h4 class="atx" id="advantage-of-openmp">Advantage of OpenMP</h4>
<ul>
<li>OpenMP offers ease of programming with minimal changes to the original code.</li>
</ul>
<h4 class="atx" id="challenges-of-openmp">Challenges of OpenMP</h4>
<ul>
<li><p>While OpenMP provides task-level parallelism, it lacks the ability to exploit fine-grained data-level parallelism inherent in ray tracing computations.</p>
</li>
<li><p>CPUs typically do not match the computational throughput of GPUs for highly parallel workloads, especially for operations like ray-scene intersection tests or shading calculations.</p>
</li>
<li><p>OpenMP also struggles with irregular memory access patterns, which are common in ray tracing due to rays traversing different regions of the scene.</p>
</li>
</ul>
<h4 class="atx" id="weakness-of-openmp">Weakness of OpenMP</h4>
<ul>
<li><p>CPUs cannot mask thread divergence as effectively as GPUs, reducing the efficiency  of numerous branching in ray tracing.</p>
</li>
<li><p>OpenMP’s performance is constrained by the limited number of CPU cores compared to GPU threads, which results in lower parallelism overall.</p>
</li>
</ul>
<p>Overall, OpenMP provides an efficient and straightforward way to accelerate ray tracing on multi-core CPUs, making it a practical solution for achieving parallelism without requiring significant code restructuring.</p>
<h3 class="atx" id="cuda-parallelism">CUDA Parallelism</h3>
<p><strong>CUDA enables fine-grained parallelism by leveraging the massive computational power of modern GPUs.</strong> In ray tracing, CUDA parallelizes the rendering process at the pixel level (and beyond), allowing thousands of threads to compute rays and their interactions simultaneously. In our implementation, each thread corresponds to a pixel, and the key to efficient CUDA implementation is designing thread hierarchies (blocks and grids) that map well to the GPU architecture. Similar to the assignment 2, a kernel takes in a square block of pixels on the image, in which rays of each pixel shall have a more similar start. The following is a code snippet to show you how the for loop is transformer to kernel launch.</p>
<pre><code class="fenced-code-block language-cpp"><span class="token comment">// CUDA Kernel</span>
__global__ <span class="token keyword">void</span> <span class="token function">ray_tracing_kernel</span><span class="token punctuation">(</span>Image image<span class="token punctuation">,</span> World world<span class="token punctuation">,</span> <span class="token keyword">int</span> max_depth<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token comment">// Calculate pixel index based on thread and block IDs</span>
    <span class="token keyword">int</span> x <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
    <span class="token keyword">int</span> y <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>y <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>y <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">;</span>

    <span class="token comment">// Ensure pixel is within image bounds</span>
    <span class="token keyword">if</span> <span class="token punctuation">(</span>x <span class="token operator">&gt;=</span> image<span class="token punctuation">.</span>width <span class="token operator">||</span> y <span class="token operator">&gt;=</span> image<span class="token punctuation">.</span>height<span class="token punctuation">)</span> <span class="token keyword">return</span><span class="token punctuation">;</span>

    Color pixel_color <span class="token operator">=</span> <span class="token function">Color</span><span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token keyword">int</span> sample <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> sample <span class="token operator">&lt;</span> num_samples_per_pixel<span class="token punctuation">;</span> sample<span class="token operator">++</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
        Ray ray <span class="token operator">=</span> <span class="token function">SampleRayFromCameraToPixel</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">;</span>
        pixel_color <span class="token operator">+=</span> <span class="token function">iterative_ray_color</span><span class="token punctuation">(</span>ray<span class="token punctuation">,</span> world<span class="token punctuation">,</span> max_depth<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
    image<span class="token punctuation">.</span><span class="token function">set_pixel</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> pixel_color <span class="token operator">/</span> num_samples_per_pixel<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token comment">// Host function to launch the kernel</span>
<span class="token keyword">void</span> <span class="token function">render</span><span class="token punctuation">(</span>Image image<span class="token punctuation">,</span> World world<span class="token punctuation">,</span> <span class="token keyword">int</span> max_depth<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    dim3 <span class="token function">block_dim</span><span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">,</span> <span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// Threads per block</span>
    dim3 <span class="token function">grid_dim</span><span class="token punctuation">(</span><span class="token punctuation">(</span>image<span class="token punctuation">.</span>width <span class="token operator">+</span> block_dim<span class="token punctuation">.</span>x <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> block_dim<span class="token punctuation">.</span>x<span class="token punctuation">,</span>
                  <span class="token punctuation">(</span>image<span class="token punctuation">.</span>height <span class="token operator">+</span> block_dim<span class="token punctuation">.</span>y <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">/</span> block_dim<span class="token punctuation">.</span>y<span class="token punctuation">)</span><span class="token punctuation">;</span>

    ray_tracing_kernel<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span>grid_dim<span class="token punctuation">,</span> block_dim<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>image<span class="token punctuation">,</span> world<span class="token punctuation">,</span> max_depth<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">cudaDeviceSynchronize</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span></code></pre>
<p>While GPUs are optimized for high-throughput computation, but they are not designed to handle deep recursion efficiently due to limited stack size. As a result, recursive ray tracing algorithms must be converted to iterative versions for CUDA. The key idea is to manage ray interactions (scattering, reflection, etc.) using an explicit stack or loop and maintain temporay variables for the dependencies between iterations. This avoids GPU stack overflow and ensures better control over the parallel execution. The iterative version of <code>ray_color</code> function is shown below.</p>
<pre><code class="fenced-code-block language-python"><span class="token keyword">def</span> <span class="token function">ray_color</span><span class="token punctuation">(</span>depth<span class="token punctuation">,</span> ray<span class="token punctuation">,</span> world<span class="token punctuation">,</span> lights<span class="token punctuation">)</span><span class="token punctuation">:</span>
    final_color <span class="token operator">=</span> color<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
    cur_attenuation <span class="token operator">=</span> color<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    cur_ray <span class="token operator">=</span> ray

    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>depth<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># Check if the ray hits anything in the world</span>
        <span class="token keyword">if</span> cur_ray hits anything <span class="token keyword">in</span> world<span class="token punctuation">:</span>
            material <span class="token operator">=</span> HitRecord<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token comment"># Add background color and return if no hit</span>
            final_color <span class="token operator">+=</span> cur_attenutaion <span class="token operator">*</span> background_color
            <span class="token keyword">return</span> final_color

        <span class="token comment"># Compute the emitted color from the material</span>
        emitted_color <span class="token operator">=</span> material<span class="token punctuation">.</span>emit<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># Only light source emit color</span>

        <span class="token comment"># Check if the material scatters the ray</span>
        <span class="token keyword">if</span> rec<span class="token punctuation">.</span>material<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            attenuation<span class="token punctuation">,</span> scattering_ray <span class="token operator">=</span> ScatterRecord<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token comment"># Add emitted color and return if no scattering</span>
            final_color <span class="token operator">+=</span> cur_attenutaion <span class="token operator">*</span> emitted_color
            <span class="token keyword">return</span> final_color

        <span class="token comment"># Add emited color to final color</span>
        final_color <span class="token operator">+=</span> cur_attenuation <span class="token operator">*</span> emmited_color
        <span class="token comment"># Update current attenuation and current ray</span>
        cur_attenuation <span class="token operator">*=</span> attenuation
        cur_ray <span class="token operator">=</span> scattered_ray

    <span class="token keyword">return</span> final_color</code></pre>
<h4 class="atx" id="advantages-of-cuda-in-ray-tracing">Advantages of CUDA in Ray Tracing</h4>
<ul>
<li><strong>Massive Parallelism</strong>: CUDA enables fine-grained parallelism, allowing each thread to handle individual rays or samples. Thousands of threads execute simultaneously, dramatically speeding up computation.</li>
<li><strong>High Throughput</strong>: GPUs excel at handling the arithmetic-heavy operations required for ray-scene intersections, material shading, and global illumination.</li>
<li><strong>Optimized for Data-Level Parallelism</strong>: CUDA exploits the inherent parallelism in ray tracing computations, such as computing intersections and sampling rays independently.</li>
<li><strong>Customizability</strong>: The thread-block-grid hierarchy allows flexible mapping of computation to hardware resources, optimizing for scene complexity and image size.</li>
</ul>
<h4 class="atx" id="challenges-of-cuda-in-ray-tracing"><strong>Challenges of CUDA in Ray Tracing</strong></h4>
<ul>
<li><strong>Branch Divergence</strong>: In ray tracing, threads in a warp often take different execution paths (e.g., hitting different objects or scattering differently), leading to inefficiencies in the SIMT (Single Instruction, Multiple Thread) model.</li>
<li><strong>Memory Access Patterns</strong>: Rays traverse different parts of the scene, causing scattered memory accesses, which degrade performance due to cache misses.</li>
<li><strong>Recursion Conversion</strong>: Converting recursive algorithms to iterative forms is non-trivial and requires explicit management of stack-like behavior, adding complexity to the code.</li>
<li><strong>Hardware-Specific Tuning</strong>: CUDA implementations require careful tuning to balance thread occupancy, memory bandwidth, and computational throughput, which can vary across GPU architectures.</li>
</ul>
<h4 class="atx" id="weaknesses-of-cuda">Weaknesses of CUDA</h4>
<ul>
<li><strong>Limited Stack Size</strong>: GPUs cannot handle deep recursion, necessitating iterative reformulation, which can complicate code design.</li>
<li><strong>Warp-Level Constraints</strong>: Branch divergence within warps reduces GPU efficiency.</li>
</ul>
<p>Overall, GPUs are highly optimized for rendering tasks due to their architecture, which is designed for massive parallelism and high arithmetic intensity. Rendering involves repetitive, independent computations like ray-object intersections, shading, and sampling, which GPUs handle efficiently with thousands of lightweight threads. The SIMD nature of GPUs allows them to process large datasets concurrently, while their high memory bandwidth supports the frequent access to textures, scene data, and acceleration structures (e.g., BVH).</p>
<h3 class="atx" id="bounding-volume-hierarchy-bvh">Bounding Volume Hierarchy (BVH)</h3>
<p>Bounding Volume Hierarchy (BVH) is a tree-based acceleration structure used in ray tracing to optimize ray-object intersection tests. BVH organizes the objects in the scene into a hierarchy of bounding volumes, which enables efficient pruning of intersection tests, as rays can quickly skip branches of the tree whose bounding volumes they do not intersect. <strong>BVH reduce the average time of searching from O(N) to O(logN).</strong></p>
<h3 class="atx" id="tree-structure-of-bvh">Tree Structure of BVH</h3>
<p>The BVH is a binary tree where:</p>
<ul>
<li>Each <strong>leaf node</strong> represents a single geometric object or a small group of objects.</li>
<li>Each <strong>internal node</strong> contains a bounding volume (typically an axis-aligned bounding box, AABB) that encapsulates all the objects in its subtree.</li>
</ul>
<p>The root node's bounding volume encloses the entire scene, and each child node's bounding volume contains a subset of the objects.</p>
<h4 class="atx" id="using-bvh-for-ray-object-intersection">Using BVH for Ray-Object Intersection</h4>
<p>The core idea of using BVH is to test a ray against the bounding volumes rather than individual objects. If a ray intersects a bounding box, we recursively or iteratively test the ray against its children. If it intersects, the function recursively checks the left and right children. Otherwise, the entire subtree is skipped.The two pesudo code of recursive and iterative versions of BVH intersection are shown below. For GPU-based ray tracing, recursion is replaced by an explicit stack.</p>
<h5 class="atx" id="bvh-intersection-recursive">BVH Intersection (Recursive)</h5>
<pre><code class="fenced-code-block language-python"><span class="token keyword">def</span> <span class="token function">bvh_node_hit</span><span class="token punctuation">(</span>ray<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> ray hits my_bounding_box<span class="token punctuation">:</span>
        hit_left <span class="token operator">=</span> left_child<span class="token punctuation">.</span>bvh_node_hit<span class="token punctuation">(</span>ray<span class="token punctuation">)</span>
        hit_right <span class="token operator">=</span> right_child<span class="token punctuation">.</span>bvh_node_hit<span class="token punctuation">(</span>ray<span class="token punctuation">)</span>
        <span class="token keyword">return</span> hit_left <span class="token keyword">or</span> hit_right
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token boolean">False</span></code></pre>
<h5 class="atx" id="bvh-intersection-iterative-for-gpu">BVH Intersection (Iterative for GPU)</h5>
<pre><code class="fenced-code-block language-python"><span class="token keyword">def</span> <span class="token function">bvh_node_hit</span><span class="token punctuation">(</span>ray<span class="token punctuation">)</span><span class="token punctuation">:</span>
    stack<span class="token punctuation">.</span>push<span class="token punctuation">(</span>root<span class="token punctuation">)</span>
    <span class="token keyword">while</span> stack <span class="token keyword">not</span> empty<span class="token punctuation">:</span>
        current <span class="token operator">=</span> stack<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> ray hits current<span class="token punctuation">.</span>bounding_box<span class="token punctuation">:</span>
            stack<span class="token punctuation">.</span>push<span class="token punctuation">(</span>left_child<span class="token punctuation">)</span>
            stack<span class="token punctuation">.</span>push<span class="token punctuation">(</span>right_child<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token keyword">continue</span></code></pre>
<h4 class="atx" id="constructing-the-bvh">Constructing the BVH</h4>
<p>The BVH is constructed by organizing objects into bounding volumes in a way that minimizes overlap between sibling nodes. This involves two key steps: <strong>bounding box creation</strong> and <strong>tree construction</strong>.</p>
<h5 class="atx" id="bounding-box-creation">Bounding Box Creation</h5>
<p>A bounding box (usually AABB) is a volume that tightly encloses one or more objects. For a group of objects, their bounding box is the smallest AABB that contains all individual bounding boxes. This encapsulation is fundamental for the BVH's efficiency, as it allows quick rejection of rays that do not intersect the bounding box.</p>
<h5 class="atx" id="tree-construction">Tree Construction</h5>
<p>To construct the BVH, the objects are recursively subdivided into groups:</p>
<ol>
<li><strong>Divide by the Longest Axis</strong>: Objects are sorted along the longest axis of their bounding box, splitting the list into two groups of roughly equal size.</li>
<li><strong>Recursive Construction</strong>: For each group, a bounding volume is created, and the process repeats until each leaf node contains one or two objects.</li>
<li><strong>Iterative Construction</strong>: On GPU, we follow the same idea except that we use an explicit stack to track all the objects.</li>
</ol>
<p>The pseudo code of recursive and iterative BVH construction are shown below.</p>
<h5 class="atx" id="recursive-tree-construction">Recursive Tree Construction</h5>
<pre><code class="fenced-code-block language-python"><span class="token keyword">def</span> <span class="token function">create_bvh_node</span><span class="token punctuation">(</span>objects<span class="token punctuation">,</span> start<span class="token punctuation">,</span> end<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># Create a bounding box that can hold all the objects</span>
    bounding_box <span class="token operator">=</span> CreateBoundingBox<span class="token punctuation">(</span>objects<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment"># Create child nodes</span>
    object_span <span class="token operator">=</span> end <span class="token operator">-</span> start
    <span class="token comment"># This adds actual object as child</span>
    <span class="token keyword">if</span> object_span <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
        left_child <span class="token operator">=</span> right_child <span class="token operator">=</span> objects<span class="token punctuation">[</span>start<span class="token punctuation">]</span>
    <span class="token keyword">elif</span> object_span <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">:</span>
        left_child<span class="token punctuation">,</span> right_child <span class="token operator">=</span> objects<span class="token punctuation">[</span>start<span class="token punctuation">]</span><span class="token punctuation">,</span> objects<span class="token punctuation">[</span>end<span class="token punctuation">]</span>
    <span class="token comment"># This adds new bvh node as child</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token comment"># Divide at the longest axis</span>
        sort_objects<span class="token punctuation">(</span>longest_axis<span class="token punctuation">)</span>
        mid <span class="token operator">=</span> start <span class="token operator">+</span> object_span <span class="token operator">/</span> <span class="token number">2</span>
        left_child <span class="token operator">=</span> create_bvh_node<span class="token punctuation">(</span>objects<span class="token punctuation">,</span> start<span class="token punctuation">,</span> mid<span class="token punctuation">)</span>
        right_child <span class="token operator">=</span> create_bvh_node<span class="token punctuation">(</span>objects<span class="token punctuation">,</span> mid<span class="token punctuation">,</span> end<span class="token punctuation">)</span>
    <span class="token keyword">return</span> bvh_node<span class="token punctuation">(</span>left_child<span class="token punctuation">,</span> right_child<span class="token punctuation">)</span></code></pre>
<h5 class="atx" id="iterative-tree-construction-for-gpu">Iterative Tree Construction for GPU</h5>
<pre><code class="fenced-code-block language-python"><span class="token keyword">def</span> <span class="token function">create_bvh_node</span><span class="token punctuation">(</span>objects<span class="token punctuation">,</span> start<span class="token punctuation">,</span> end<span class="token punctuation">)</span><span class="token punctuation">:</span>
    root <span class="token operator">=</span> bvh_node<span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
    stack<span class="token punctuation">.</span>push<span class="token punctuation">(</span><span class="token punctuation">(</span>root<span class="token punctuation">,</span> start<span class="token punctuation">,</span> end<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">while</span> stack <span class="token keyword">not</span> empty<span class="token punctuation">:</span>
        current<span class="token punctuation">,</span> cur_start<span class="token punctuation">,</span> cur_end <span class="token operator">=</span> stack<span class="token punctuation">.</span>pop<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># Create a bounding box that can hold all the objects</span>
        bounding_box <span class="token operator">=</span> CreateBoundingBox<span class="token punctuation">(</span>objects<span class="token punctuation">[</span>cur_start<span class="token punctuation">:</span>cur_end<span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token comment"># Create child nodes</span>
        <span class="token comment"># This adds actual object as child</span>
        <span class="token keyword">if</span> object_span <span class="token operator">==</span> <span class="token number">1</span><span class="token punctuation">:</span>
            left_child <span class="token operator">=</span> right_child <span class="token operator">=</span> objects<span class="token punctuation">[</span>start<span class="token punctuation">]</span>
        <span class="token keyword">elif</span> object_span <span class="token operator">==</span> <span class="token number">2</span><span class="token punctuation">:</span>
            left_child<span class="token punctuation">,</span> right_child <span class="token operator">=</span> objects<span class="token punctuation">[</span>start<span class="token punctuation">]</span><span class="token punctuation">,</span> objects<span class="token punctuation">[</span>end<span class="token punctuation">]</span>
        <span class="token comment"># This adds new bvh node as child</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token comment"># Divide at the longest axis</span>
            sort_objects<span class="token punctuation">(</span>longest_axis<span class="token punctuation">)</span>
            mid <span class="token operator">=</span> start <span class="token operator">+</span> object_span <span class="token operator">/</span> <span class="token number">2</span>
            current<span class="token punctuation">.</span>left_child <span class="token operator">=</span> bvh_node<span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
            stack<span class="token punctuation">.</span>push<span class="token punctuation">(</span><span class="token punctuation">(</span>current<span class="token punctuation">.</span>left_child<span class="token punctuation">,</span> start<span class="token punctuation">,</span> mid<span class="token punctuation">)</span><span class="token punctuation">)</span>
            current<span class="token punctuation">.</span>right_child <span class="token operator">=</span> bvh_node<span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span> <span class="token boolean">None</span><span class="token punctuation">)</span>
            stack<span class="token punctuation">.</span>push<span class="token punctuation">(</span><span class="token punctuation">(</span>current<span class="token punctuation">.</span>right_child<span class="token punctuation">,</span> mid<span class="token punctuation">,</span> end<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> root</code></pre>
<h4 class="atx" id="balancing-the-bvh"><strong>Balancing the BVH</strong></h4>
<p>A balanced BVH minimizes the depth of the tree, ensuring that rays do not have to traverse unnecessarily deep paths. This is achieved by:</p>
<ul>
<li>Dividing objects equally at each level.</li>
<li>Sorting along the longest axis to reduce overlap between sibling bounding volumes.</li>
<li>Using heuristics like the Surface Area Heuristic (SAH) to optimize splitting planes.</li>
</ul>
<p>Overall, BVH is a powerful acceleration structure that significantly improves ray tracing efficiency by hierarchically organizing objects in the scene. By using bounding volumes to cull large parts of the scene, the number of ray-object intersection tests is drastically reduced. Recursive and iterative traversal methods are employed depending on the hardware, with explicit stacks used to handle GPU constraints. Proper tree balancing and bounding box creation are critical for maximizing the BVH's effectiveness, ensuring fast and efficient ray tracing for complex scenes.</p>
<h2 class="atx" id="results">Results</h2>
<h3 class="atx" id="deliverable-results">Deliverable Results</h3>
<blockquote>
<p>We have achieved all the <em>Plan to achieve</em> and <em>Hope to Achieve</em> in the proposal.</p>
<ul>
<li><p>Rendering of basic 3D objects (sphere, quad, triangle)</p>
</li>
</ul>
<ul>
<li><p>Basic shading</p>
</li>
<li><p>Light reflection, refraction, emission on basic materials</p>
</li>
<li><p>Basic textures and perlin noise</p>
</li>
<li><p>Basic light sources</p>
</li>
<li><p>Monte Carlo Sampling</p>
</li>
<li><p>Importance Sampling</p>
</li>
<li><p>Light Sampling</p>
</li>
<li><p>Bounding Volume Hierarchies (BVH) for optimized ray-object intersection checks</p>
</li>
<li><p>Animation of moving camera (both) and moving sphere (CPU only)</p>
</li>
</ul>
</blockquote>
<ul>
<li><p>An application (See <strong>Github Repo</strong>) that can run ray tracing of four scenes on both CPU and GPU on GHC machines.</p>
</li>
<li><p>A website (See <strong>Website URL)</strong> demonstrating our rendered images and movement of first scene, as well as the project propsoal, milestone report, final report, presentation poster and github repository.</p>
</li>
</ul>
<h3 class="atx" id="rendering-scenes">Rendering Scenes</h3>
<blockquote>
<p>There are four scenes we supported, the first three scenes come from the "Ray Tracing in One Weekend" series and the last scene mimics how complicate objects actually are in real rendering, where a single object is composed of many small meshes (trianlges) and form the appearance of an object.</p>
</blockquote>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">First Scene</th>
<th align="center">Cornell Box</th>
<th align="center">Final Scene</th>
<th align="center">Mesh Scene</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Number of Objects</td>
<td align="center">488</td>
<td align="center">13</td>
<td align="center">3,409</td>
<td align="center">4974</td>
</tr>
</tbody></table>
<h4 class="atx" id="first-scene">First Scene</h4>
<img data-align="center" alt="first_scene.png" title="" src="../images/first_scene.png">

<h4 class="atx" id="cornell-box">Cornell Box</h4>
<img data-align="center" alt="cornell_box.png" title="" src="../images/cornell_box.png">

<h4 class="atx" id="final-scene">Final Scene</h4>
<img data-align="center" alt="final_scene.png" title="" src="../images/final_scene.png">

<h4 class="atx" id="mesh-scene">Mesh Scene</h4>
<img data-align="center" alt="mesh_scene.png" title="" src="../images/mesh_scene.png">

<h3 class="atx" id="performance-accerelation">Performance Accerelation</h3>
<h4 class="atx" id="experiment-setup">Experiment Setup</h4>
<blockquote>
<p>The following results are all obtained on GHC Machines using 8-core i7-9700 CPU and RTX 2080 GPU. Machines used involve GHC 28, GHC 29, GHC 45, GHC 46, GHC 47, GHC 48, GHC 49 and GHC 77. All rendered images are of equal size <code>600 x 600</code> and the configuration are set to  <code>samples_per_pixel=200</code> and <code>max_depth=20</code>. Runtime is in milliseconds and acceleration is in times. Speedup analysis are only showing visualization here, the table can be found in the <code>APPENDIX</code> section.</p>
</blockquote>
<h4 class="atx" id="comparison-of-cpu-and-gpu-performance">Comparison of CPU and GPU Performance</h4>
<p>The table and the accompanying visualization illustrate the rendering performance across three methods: <strong>Baseline</strong> (single-threaded CPU), <strong>OpenMP</strong> (multi-core CPU), and <strong>CUDA</strong> (GPU), both with and without BVH acceleration. The runtime and speedup are presented, and the impact of BVH on performance is evaluated. Observations include scaling of runtime with problem size, speedup achieved through parallelism, and limitations in performance scaling. A very detailed table showing the runtime of each method and their relative speedups is given below.</p>
<p>Here is a summary of our findings:</p>
<ul>
<li>Baseline exhibits extremely high runtime.</li>
<li>OpenMP doesn't scale well.</li>
<li>CUDA outperforms other methods dramatically due to fine-grained parallelism.</li>
<li>BVH accelerates complex scenes.</li>
</ul>
<table>
<thead>
<tr>
<th align="center">Methods</th>
<th align="center">First Scene</th>
<th align="center">Cornell Box</th>
<th align="center">Final Scene</th>
<th align="center">Mesh Scene</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Number of Objects</td>
<td align="center">488</td>
<td align="center">13</td>
<td align="center">3409</td>
<td align="center">4974</td>
</tr>
<tr>
<td align="center">Baseline without BVH Runtime(ms)/Speedup</td>
<td align="center">8,656,150 (1x)</td>
<td align="center">727,679 (1x)</td>
<td align="center">32,564,886 (1x)</td>
<td align="center">51,849,900 (1x)</td>
</tr>
<tr>
<td align="center">Baseline with BVH Runtime(ms)/Speedup</td>
<td align="center">1,588,860&nbsp;(5.45x)</td>
<td align="center">772,366 (0.94x)</td>
<td align="center">1,127,800 (28.87x)</td>
<td align="center">1,105,260 (46.91x)</td>
</tr>
<tr>
<td align="center">OpenMP without BVH Runtime(ms)/Speedup</td>
<td align="center">2,742,760 (3.16x)</td>
<td align="center">231,167 (3.15x)</td>
<td align="center">10,638,643 (3.06x)</td>
<td align="center">12,174,500 (4.26x)</td>
</tr>
<tr>
<td align="center">OpenMP with BVH Runtime(ms)/Speedup</td>
<td align="center">532,700 (16.25x)</td>
<td align="center">237,790 (3.06x)</td>
<td align="center">364,221 (89.41x)</td>
<td align="center">252,432&nbsp;(205.40x)</td>
</tr>
<tr>
<td align="center">CUDA without BVH Runtime(ms)/Speedup</td>
<td align="center">53,391(162.13x)</td>
<td align="center">5,766 (126.20x)</td>
<td align="center">359,111 (90.68x)</td>
<td align="center">779,770 (66.49x)</td>
</tr>
<tr>
<td align="center">CUDA with BVH Runtime(ms)/Speedup</td>
<td align="center">10,916&nbsp;(792.98x)</td>
<td align="center">5,485 (132.67x)</td>
<td align="center">26,530&nbsp;(1227.47x)</td>
<td align="center">6,020&nbsp;(<strong>8612.94x</strong>)</td>
</tr>
</tbody></table>
<h5 class="atx" id="runtime-trends">Runtime Trends</h5>
<p>As observed, runtime significantly drops with OpenMP and CUDA in all scenes. The CUDA implementation with BVH shows the largest reduction in runtime. A figure is shown below to visualize this huge runtime difference, note that the y-axis is in <code>log</code> scale.</p>
<ul>
<li><p><strong>Baseline Without BVH</strong>: Runtime grows drastically with scene complexity because each ray performs brute-force intersection checks.</p>
</li>
<li><p><strong>Baseline With BVH</strong>: BVH significantly reduces runtime for larger scenes (Final Scene and Mesh Scene) by pruning unnecessary ray-object intersections.</p>
</li>
<li><p><strong>OpenMP Without BVH</strong>: OpenMP achieves moderate speedup (3x-4x) due to task-level parallelism. However, the scaling of speedup with number of cores are not satisfying, plateaus at merely 4 thread counts. This is possibly due to parallelization overhead and shared memory bottlenecks.</p>
</li>
<li><p><strong>OpenMP With BVH</strong>: BVH further reduces runtime, particularly for complex scenes, achieving up to 205x speedup (Mesh Scene). However the speedup is still limited compared to CUDA because CPUs lack fine-grained parallelism.</p>
</li>
<li><p><strong>CUDA Without BVH</strong>: CUDA achieves massive speedup (e.g., 162x for First Scene), leveraging GPU’s thousands of lightweight threads.</p>
</li>
<li><p><strong>CUDA With BVH</strong>: BVH accelerates CUDA further, achieving <strong>8612x speedup</strong> for the Mesh Scene. CUDA’s hierarchical memory access and parallelization of BVH traversal ensure excellent performance.</p>
</li>
</ul>
<img data-align="center" alt="FinalReportResultFigure2.png" title="" src="../images/FinalReportResultFigure2.png">

<h5 class="atx" id="impact-of-bvh-acceleration"><strong>Impact of BVH Acceleration</strong></h5>
<ul>
<li><p>BVH is critical in accelerating ray tracing in complex scenes across all methods.</p>
</li>
<li><p><strong>Baseline Method</strong>: Without BVH, the rendering time is extremely high, especially for complex scenes like the Final Scene (9 Hours) and the Mesh Scene (14.5 Hours). Introducing BVH reduces the runtime drastically by <strong>85%–95%</strong>, indicating BVH's effectiveness in pruning unnecessary ray-object intersections.</p>
</li>
<li><p><strong>OpenMP Method</strong>: Similar to Baseline, BVH acceleration significantly improves performance. Since both methods are running on CPU, it has similar accerelation.</p>
</li>
<li><p><strong>CUDA Method</strong>: BVH further accelerates GPU performance. For instance, in the <strong>First Scene</strong>, the runtime improves from <strong>53s</strong> to <strong>10s</strong>; in the <strong>Mesh Scene</strong>, the runtime improves from <strong>779s</strong> to <strong>6s</strong>, achieving <strong>129x</strong> speedup. CUDA’s ability to efficiently handle BVH traversal with massive parallelism highlights the synergy between BVH and GPU architectures.</p>
</li>
<li><p><strong>Why Cornell Box Has Worset Acceleration</strong>: Cornell Box has only 13 objects, where BVH's overhead outweighs its benefits.</p>
</li>
<li><p><strong>Why Mesh Scene Has Best Acceleration</strong>: Large number of small meshes clustered togther, benefits most from BVH pruning. The parellel traversal in this scene also tenders to have th least divergence in branching until the last few layers.</p>
</li>
<li><p><strong>Why BVH Speedup Scales</strong>:</p>
<ul>
<li>More complex scenes have more unnecessary intersections, which BVH effectively prunes.</li>
<li>GPU-based BVH traversal benefits from reduced memory-bound operations and parallel stack management.</li>
</ul>
</li>
</ul>
<img data-align="center" alt="FinalReportResultFigure4.png" title="" src="../images/FinalReportResultFigure4.png">

<h5 class="atx" id="analysis-of-openmp-and-cuda-parallelism">Analysis of OpenMP and CUDA Parallelism</h5>
<ul>
<li><p><strong>OpenMP: Achieves limited speedup</strong> by utilizing task-level parallelism across CPU cores.</p>
</li>
<li><p><strong>CUDA: Achieves massive speedup</strong> by leveraging GPU’s fine-grained parallelism and optimized memory hierarchy.</p>
</li>
</ul>
<img data-align="center" alt="FinalReportResultFigure3.png" src="../images/FinalReportResultFigure3.png" title="">

<h4 class="atx" id="further-analysis-of-openmp-acceleration-with-number-of-cores">Further Analysis of OpenMP Acceleration with Number of Cores</h4>
<p>In this experiment, we investigate the reasons behind the limited speedup observed in OpenMP when increasing the number of threads from 1 to 8. The rendering task is computationally intensive, where each pixel requires no less than <strong>50ms</strong> to compute. The expectation is that multi-core parallelism would significantly reduce the runtime. While the 1 core to 4 core improvement still exhibits significant reduction of runtime, adding more threads yields minimal improvement. However, the results show that while performance improves up to 4 threads, it stagnates between 4 and 8 threads across all scenes. We believe there are two main reasons that contribute to this problem.</p>
<table>
<thead>
<tr>
<th align="center">Runtime(ms)/Num of Cores</th>
<th align="center">First Scene</th>
<th align="center">Cornell Box</th>
<th align="center">Final Scene</th>
<th align="center">Mesh Scene</th>
</tr>
</thead>
<tbody><tr>
<td align="center">1</td>
<td align="center">1,588,860</td>
<td align="center">772,366</td>
<td align="center">1,127,800</td>
<td align="center">1,105,260</td>
</tr>
<tr>
<td align="center">2</td>
<td align="center">855,407</td>
<td align="center">434,136</td>
<td align="center">605,119</td>
<td align="center">569,984</td>
</tr>
<tr>
<td align="center">4</td>
<td align="center">542,649</td>
<td align="center">261,806</td>
<td align="center">382,038</td>
<td align="center">338,276</td>
</tr>
<tr>
<td align="center">8</td>
<td align="center">532,700</td>
<td align="center">237,790</td>
<td align="center">364,221</td>
<td align="center">252,432</td>
</tr>
</tbody></table>
<img data-align="center" alt="FinalReportResultFigure1.png" title="" src="../images/FinalReportResultFigure1.png">

<ol>
<li><p><strong>Memory Bandwidth and Cache Contention</strong></p>
<p>Ray tracing involves <strong>irregular memory access patterns</strong>, particularly when rays traverse the BVH tree or access scene geometry. The lack of spatial locality causes threads to frequently load new data from memory, which exacerbates cache contention.</p>
<ul>
<li><p><strong>Shared L3 Cache Eviction</strong>:</p>
<ul>
<li><p>In modern multi-core CPUs like the i7-9700, all cores share an L3 cache. As the number of threads increases, multiple threads access <strong>different parts of the BVH tree or objects in the scene</strong>, causing data to be evicted from the cache.</p>
</li>
<li><p>Cache misses force threads to reload data from main memory, resulting in <strong>latency</strong> and reduced throughput.</p>
</li>
</ul>
</li>
<li><p><strong>Memory Bandwidth Saturation</strong>:</p>
<ul>
<li><p>As threads load data concurrently, the shared memory bandwidth becomes saturated, limiting the overall data transfer rate.</p>
</li>
<li><p>Beyond 4 threads, memory bandwidth is nearly fully utilized, and additional threads compete for the same bandwidth, leading to diminishing returns.</p>
</li>
</ul>
</li>
<li><p><strong>Impact</strong>:</p>
<ul>
<li><p>For scenes with <strong>complex BVH structures</strong> (e.g., Final Scene and Mesh Scene), irregular accesses amplify the cache contention and memory bandwidth bottleneck.</p>
</li>
<li><p>This explains why <strong>Final Scene</strong> and <strong>Mesh Scene</strong> show limited improvement when scaling from 4 to 8 threads.</p>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>2* <strong>Scheduling and Parallelism Overhead</strong></p>
<p>   Although the per-pixel rendering time (<strong>≥50ms</strong>) is substantial, scheduling overhead can still impact performance at higher thread counts.</p>
<ul>
<li><p><strong>Dynamic Scheduling Overhead</strong>:</p>
<ul>
<li><p>The use of <code>#pragma omp parallel for schedule(dynamic)</code> ensures load balancing but adds a slight overhead due to the dynamic task assignment.</p>
</li>
<li><p>While this overhead is relatively small compared to the task size, it can accumulate as more threads are added, contributing to the stagnation of performance.</p>
</li>
</ul>
</li>
<li><p><strong>Thread Synchronization</strong>:</p>
<ul>
<li>While OpenMP splits tasks effectively, threads still incur synchronization overhead, especially when accessing shared memory resources. Combined with cache contention, synchronization further reduces scaling efficiency.</li>
</ul>
</li>
</ul>
<h2 class="atx" id="future-work-that-can-be-done-on-cuda">Future Work that Can Be Done on CUDA</h2>
<ul>
<li><p><strong>Support for Moving Objects</strong></p>
<ul>
<li>Implement incremental BVH updates or GPU-optimized BVH builders like <strong>LBVH</strong> to handle BVH reconstruction efficiently for moving objects.</li>
</ul>
</li>
<li><p><strong>Memory Access Optimization</strong></p>
<ul>
<li>Rearrange BVH nodes to improve spatial locality and reduce cache misses.</li>
<li>Use shared memory to store frequently accessed BVH data for threads in the same block.</li>
</ul>
</li>
<li><p><strong>Advanced BVH Traversal</strong></p>
<ul>
<li>Explore <strong>stackless traversal</strong> (e.g., rope-based BVH) to reduce memory overhead.</li>
<li>Use <strong>persistent threads</strong> to dynamically fetch rays, improving GPU utilization.</li>
</ul>
</li>
<li><p><strong>Adaptive Sampling</strong></p>
<ul>
<li>Dynamically allocate more samples to high-variance regions (e.g., edges or reflections) to reduce overall computation.</li>
</ul>
</li>
<li><p><strong>Post-Processing Denoising</strong></p>
<ul>
<li>Integrate GPU-based denoisers like <strong>NVIDIA OptiX AI denoiser</strong> to improve image quality with fewer samples.</li>
</ul>
</li>
</ul>
<h2 class="atx" id="reference">REFERENCE</h2>
<p>[1] <a href="https://raytracing.github.io/books/RayTracingInOneWeekend.html"><em>Ray Tracing in One Weekend</em></a></p>
<p>[2] <a href="https://raytracing.github.io/books/RayTracingTheNextWeek.html">Ray Tracing: The Next Week</a></p>
<p>[3] <a href="https://raytracing.github.io/books/RayTracingTheRestOfYourLife.html">Ray Tracing: The Rest of Your Life</a></p>
<p>[4] <a href="https://developer.nvidia.com/blog/accelerated-ray-tracing-cuda/">Accelerated Ray Tracing in One Weekend in CUDA | NVIDIA Technical Blog</a></p>
<p>[5] <a href="https://developer.nvidia.com/blog/thinking-parallel-part-ii-tree-traversal-gpu/">Thinking Parallel, Part II: Tree Traversal on the GPU | NVIDIA Technical Blog</a></p>
<h2 class="atx" id="distribution-of-work">DISTRIBUTION OF WORK</h2>
<p>Work is equally distributed between Jiaqi Song and Xinping Luo (50% - 50%). You can find a detailed schedule in the <code>APPENDIX</code>.</p>
<h2 class="atx" id="appendix">APPENDIX</h2>
<h3 class="atx" id="pseudo-code-with-sampling-considered">Pseudo Code with Sampling Considered</h3>
<pre><code class="fenced-code-block language-python"><span class="token triple-quoted-string string">""" Recursive Ray Color with Sampling """</span>
<span class="token keyword">def</span> <span class="token function">ray_color</span><span class="token punctuation">(</span>depth<span class="token punctuation">,</span> ray<span class="token punctuation">,</span> world<span class="token punctuation">,</span> lights<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token comment"># If the recursion depth is zero or less, return black</span>
    <span class="token keyword">if</span> depth <span class="token operator">&lt;=</span> <span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> Color<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>

    <span class="token comment"># Check if the ray hits anything in the world</span>
    <span class="token keyword">if</span> ray hits anything <span class="token keyword">in</span> world<span class="token punctuation">:</span>
        <span class="token comment"># rec contains hit_point, material</span>
        rec <span class="token operator">=</span> HitRecord<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> background_color <span class="token comment"># Return the background color if no hit</span>

    <span class="token comment"># Compute the emitted color from the material</span>
    emitted_color <span class="token operator">=</span> rec<span class="token punctuation">.</span>material<span class="token punctuation">.</span>emit<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># Only light source emit color</span>

    <span class="token comment"># Check if the material scatters the ray</span>
    <span class="token keyword">if</span> rec<span class="token punctuation">.</span>material<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># srec contains skip_pdf, attenuation, scattering_pdf</span>
        srec <span class="token operator">=</span> ScatterRecord<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> emitted_color  <span class="token comment"># Return emitted color if no scattering</span>

    <span class="token comment"># Handle special case for skip PDF</span>
    <span class="token keyword">if</span> srec<span class="token punctuation">.</span>skip_pdf<span class="token punctuation">:</span>
        <span class="token keyword">return</span> srec<span class="token punctuation">.</span>attenuation <span class="token operator">*</span> \
            ray_color<span class="token punctuation">(</span>depth <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> no_pdf_scatter_ray<span class="token punctuation">,</span> world<span class="token punctuation">,</span> lights<span class="token punctuation">)</span>

    <span class="token comment"># Combine the light source PDF and the material PDF</span>
    mix_pdf <span class="token operator">=</span> MixPDF<span class="token punctuation">(</span>LightPDF<span class="token punctuation">(</span>lights<span class="token punctuation">,</span> rec<span class="token punctuation">.</span>hit_point<span class="token punctuation">)</span><span class="token punctuation">,</span> rec<span class="token punctuation">.</span>material<span class="token punctuation">.</span>pdf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment"># Generate a scattered ray using the combined PDF</span>
    scattered_ray <span class="token operator">=</span> generate_most_likely_ray<span class="token punctuation">(</span>rec<span class="token punctuation">.</span>hit_point<span class="token punctuation">,</span> mix_pdf<span class="token punctuation">)</span> 
    <span class="token comment"># Generate the pdf value of scattered ray</span>
    pdf_value <span class="token operator">=</span> mix_pdf<span class="token punctuation">.</span>value<span class="token punctuation">(</span>scattered_ray<span class="token punctuation">.</span>direction<span class="token punctuation">)</span>

    <span class="token comment"># Recursively call ray_color to get the color of scattered ray</span>
    recursive_color <span class="token operator">=</span> ray_color<span class="token punctuation">(</span>depth <span class="token operator">-</span> <span class="token number">1</span><span class="token punctuation">,</span> scattered_ray<span class="token punctuation">,</span> world<span class="token punctuation">,</span> lights<span class="token punctuation">)</span>

    <span class="token comment"># Compute the color contribution from scattering</span>
    scattered_color <span class="token operator">=</span> <span class="token punctuation">(</span>srec<span class="token punctuation">.</span>attenuation <span class="token operator">*</span> \
        srec<span class="token punctuation">.</span>scattering_pdf <span class="token operator">*</span> recursive_color<span class="token punctuation">)</span> <span class="token operator">/</span> pdf_value

    <span class="token comment"># Return the total color (emission + scattered light)</span>
    <span class="token keyword">return</span> emitted_color <span class="token operator">+</span> scattered_color</code></pre>
<pre><code class="fenced-code-block language-python"><span class="token triple-quoted-string string">""" Recursive Ray Color with Sampling """</span>
<span class="token keyword">def</span> <span class="token function">ray_color</span><span class="token punctuation">(</span>depth<span class="token punctuation">,</span> ray<span class="token punctuation">,</span> world<span class="token punctuation">,</span> lights<span class="token punctuation">)</span><span class="token punctuation">:</span>
    final_color <span class="token operator">=</span> color<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
    cur_attenuation <span class="token operator">=</span> color<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>
    cur_ray <span class="token operator">=</span> ray

    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>depth<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token comment"># Check if the ray hits anything in the world</span>
        <span class="token keyword">if</span> cur_ray hits anything <span class="token keyword">in</span> world<span class="token punctuation">:</span>
            <span class="token comment"># rec contains hit_point, material</span>
            rec <span class="token operator">=</span> HitRecord<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token comment"># Add background color and return if no hit</span>
            final_color <span class="token operator">+=</span> cur_attenutaion <span class="token operator">*</span> background_color
            <span class="token keyword">return</span> final_color

        <span class="token comment"># Compute the emitted color from the material</span>
        emitted_color <span class="token operator">=</span> rec<span class="token punctuation">.</span>material<span class="token punctuation">.</span>emit<span class="token punctuation">(</span><span class="token punctuation">)</span>

        <span class="token comment"># Check if the material scatters the ray</span>
        <span class="token keyword">if</span> rec<span class="token punctuation">.</span>material<span class="token punctuation">.</span>scatter<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token comment"># srec contains skip_pdf, attenuation, scattering_pdf</span>
            srec <span class="token operator">=</span> ScatterRecord<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            <span class="token comment"># Add emitted color and return if no scattering</span>
            final_color <span class="token operator">+=</span> cur_attenutaion <span class="token operator">*</span> emitted_color
            <span class="token keyword">return</span> final_color

        <span class="token comment"># Handle special case for skip PDF</span>
        <span class="token keyword">if</span> srec<span class="token punctuation">.</span>skip_pdf<span class="token punctuation">:</span>
            cur_attenuation <span class="token operator">*=</span> srec<span class="token punctuation">.</span>attenuation
            cur_ray <span class="token operator">=</span> no_pdf_scatter_ray
            <span class="token keyword">continue</span>

        <span class="token comment"># Combine the light source PDF and the material PDF</span>
        mix_pdf <span class="token operator">=</span> \
            MixPDF<span class="token punctuation">(</span>LightPDF<span class="token punctuation">(</span>lights<span class="token punctuation">,</span> rec<span class="token punctuation">.</span>hit_point<span class="token punctuation">)</span><span class="token punctuation">,</span> rec<span class="token punctuation">.</span>material<span class="token punctuation">.</span>pdf<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

        <span class="token comment"># Generate a scattered ray using the combined PDF</span>
        scattered_ray <span class="token operator">=</span> generate_most_likely_ray<span class="token punctuation">(</span>rec<span class="token punctuation">.</span>hit_point<span class="token punctuation">,</span> mix_pdf<span class="token punctuation">)</span>  
        <span class="token comment"># Generate the pdf value of scattered ray</span>
        pdf_value <span class="token operator">=</span> mix_pdf<span class="token punctuation">.</span>value<span class="token punctuation">(</span>scattered_ray<span class="token punctuation">.</span>direction<span class="token punctuation">)</span>

        <span class="token comment"># Add emited color to final color</span>
        final_color <span class="token operator">+=</span> cur_attenuation <span class="token operator">*</span> emmited_color

        <span class="token comment"># Update current attenuation</span>
        cur_attenuation <span class="token operator">*=</span> \
            <span class="token punctuation">(</span>srec<span class="token punctuation">.</span>attenuation <span class="token operator">*</span> srec<span class="token punctuation">.</span>scattering_pdf<span class="token punctuation">)</span> <span class="token operator">/</span> pdf_value
        <span class="token comment"># Update current ray</span>
        cur_ray <span class="token operator">=</span> scattered_ray

    <span class="token keyword">return</span> final_color</code></pre>
<h3 class="atx" id="speedup-tables">Speedup Tables</h3>
<table>
<thead>
<tr>
<th align="center">Speedup of BVH/Method</th>
<th align="center">First Scene</th>
<th align="center">Cornell Box</th>
<th align="center">Final Scene</th>
<th align="center">Mesh Scene</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Baseline</td>
<td align="center">5.448025628</td>
<td align="center">0.942142715</td>
<td align="center">28.87469941</td>
<td align="center">46.91194832</td>
</tr>
<tr>
<td align="center">OpenMP</td>
<td align="center">5.148789187</td>
<td align="center">0.972147693</td>
<td align="center">29.20930699</td>
<td align="center">48.22882994</td>
</tr>
<tr>
<td align="center">CUDA</td>
<td align="center">4.891077318</td>
<td align="center">1.051230629</td>
<td align="center">13.53603468</td>
<td align="center">129.5299003</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th align="center">Speedup of Method/Method</th>
<th align="center">First Scene</th>
<th align="center">Cornell Box</th>
<th align="center">Final Scene</th>
<th align="center">Mesh Scene</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Baseline without BVH</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center">OpenMP without BVH</td>
<td align="center">3.1559</td>
<td align="center">3.1478</td>
<td align="center">3.0609</td>
<td align="center">4.2588</td>
</tr>
<tr>
<td align="center">CUDA without BVH</td>
<td align="center">162.1275</td>
<td align="center">126.2016</td>
<td align="center">90.6819</td>
<td align="center">66.4938</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th align="center">Speedup of Method/Method</th>
<th align="center">First Scene</th>
<th align="center">Cornell Box</th>
<th align="center">Final Scene</th>
<th align="center">Mesh Scene</th>
</tr>
</thead>
<tbody><tr>
<td align="center">Baseline without BVH</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center">OpenMP without BVH</td>
<td align="center">3.1559</td>
<td align="center">3.1478</td>
<td align="center">3.0609</td>
<td align="center">4.2588</td>
</tr>
<tr>
<td align="center">CUDA without BVH</td>
<td align="center">162.1275</td>
<td align="center">126.2016</td>
<td align="center">90.6819</td>
<td align="center">66.4938</td>
</tr>
</tbody></table>
<table>
<thead>
<tr>
<th align="center">Speedup of Multi-core/Threads</th>
<th align="center">First Scene</th>
<th align="center">Cornell Box</th>
<th align="center">Final Scene</th>
<th align="center">Mesh Scene</th>
</tr>
</thead>
<tbody><tr>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
<tr>
<td align="center">2</td>
<td align="center">1.8574</td>
<td align="center">1.7790</td>
<td align="center">1.8637</td>
<td align="center">1.9391</td>
</tr>
<tr>
<td align="center">4</td>
<td align="center">2.9279</td>
<td align="center">2.9501</td>
<td align="center">2.9520</td>
<td align="center">3.2673</td>
</tr>
<tr>
<td align="center">8</td>
<td align="center">2.9826</td>
<td align="center">3.2481</td>
<td align="center">3.0964</td>
<td align="center">4.3784</td>
</tr>
</tbody></table>
<h3 class="atx" id="project-schedule">Project Schedule</h3>
<ul>
<li><p>11/4 - 11/10</p>
<ul>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Discuss project ideas with instructors (Finished 11/4) (Jiaqi Song, Xinping Luo)</p>
</li>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Initial website design (Finished 11/9) (Jiaqi Song, Xinping Luo)</p>
</li>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Prepare start code of "Ray Tracing in One Weekend" (Finished 11/4) (Jiaqi Song, Xinping Luo)</p>
</li>
</ul>
</li>
<li><p>11/11 - 11/17</p>
<ul>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Write project proposal (due 11/13) (Jiaqi Song, Xinping Luo)</p>
</li>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Add OpenMP support to CPU code if applicable (Finished 11/14) (Jiaqi Song)</p>
</li>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Program the corresponding CUDA code of "Ray Tracing in one Weekend" (Finished 11/16) (Xinping Luo)</p>
</li>
</ul>
</li>
<li><p>11/18 - 11/24</p>
<ul>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Finish coding of book I (Finished 11/16) (Jiaqi Song, Xinping Luo)</p>
</li>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Add start code of "Ray Tracing The Next Week" (Finished 11/17) (Jiaqi Song, Xinping Luo)</p>
</li>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p><del>Add OpenMP support to new CPU code if applicable</del> (No change for Opemp in Book II and Book III)</p>
</li>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Program the corresponding CUDA code of "Ray Tracing the next week" (Finished 11/18) (Jiaqi Song, Xinping Luo)</p>
</li>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Add triangle object in "Ray Tracing the Rest of Your Life" (Finished 11/19) (Jiaqi Song)</p>
</li>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Animation on CPU (moving camera and moving objects) (Jiaqi Song)</p>
</li>
</ul>
</li>
<li><p>11/25 - 12/1</p>
<ul>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Finish coding of book II (Finished 11/17) (Jiaqi Song, Xinping Luo)</p>
</li>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Finish coding of new features from book III (Finished 11/19) (Jiaqi Song, Xinping Luo)</p>
</li>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Perform experiments on existing code and compare the performance of three versions of code (Finished 11/21) (Jiaqi Song, Xinping Luo)</p>
</li>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Write milestone report (due 12/2) (Finished 11/30) (Jiaqi Song, Xinping Luo)</p>
</li>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Update the website content (Finished 11/30) (Jiaqi Song, Xinping Luo)</p>
</li>
</ul>
</li>
<li><p>12/2 - 12/8</p>
<ul>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Program the corresponding CUDA code of Monte Carlo Samplings (Finished 12/2) (Xinping Luo)</p>
</li>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Program the corresponding CUDA code of BVH (Finished 12/3) (Jiaqi Song)</p>
</li>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Animation on CUDA (moving camera) (Finished 12/3) (Jiaqi Song)</p>
</li>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Do the "hope to do things" if there is still time (Finished 12/10) (Xinping Luo)</p>
</li>
</ul>
</li>
<li><p>12/8 - 12/15</p>
<ul>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Debug BVH (Finished 12/10) (Jiaqi Song, Xinping Luo)</p>
</li>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Complete coding (Finished 12/10) (Jiaqi Song, Xinping Luo)</p>
</li>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Perform experiments on final code and compare the performance of three versions of code (Finished 12/11) (Jiaqi Song, Xinping Luo)</p>
</li>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Prepare poster (Finished 12/13) (Jiaqi Song, Xinping Luo)</p>
</li>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Attend poster session (12/13) (Jiaqi Song, Xinping Luo)</p>
</li>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Write final project report (Finished 12/15) (Jiaqi Song, Xinping Luo)</p>
</li>
<li class="task-list-item"><input disabled="" checked="" type="checkbox"> <p>Update the website content (Finished 12/15) (Jiaqi Song, Xinping Luo)</p>
</li>
</ul>
</li>
</ul>
</article>
</body>
</html>